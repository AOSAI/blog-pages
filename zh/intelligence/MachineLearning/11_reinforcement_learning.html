<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.14" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.50" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://mister-hope.github.io/blog-pages/zh/intelligence/MachineLearning/11_reinforcement_learning.html"><meta property="og:site_name" content="青裁的博客"><meta property="og:title" content="3-3 强化学习"><meta property="og:description" content="强化学习（Reinforcement Learning） 1. 强化学习概述 在机器学习中，强化学习与其说是一类算法，不如说是一种思想，就和 贪心、动态规划、分治、回溯 这些经典的解决思路一样。虽然目前尚未在商业领域中得到广泛应用，但它也是机器学习的支柱之一。 我们还是从一个例子开始，图 11.1 是斯坦福大学自主研发的遥感直升机，重 32 磅。与其他..."><meta property="og:type" content="article"><meta property="og:image" content="https://mister-hope.github.io/blog-pages/machinelearning/five/11-01.png =360x"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2024-08-28T14:28:20.000Z"><meta property="article:author" content="AOSAI"><meta property="article:tag" content="强化学习"><meta property="article:published_time" content="2024-08-28T00:00:00.000Z"><meta property="article:modified_time" content="2024-08-28T14:28:20.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"3-3 强化学习","image":["https://mister-hope.github.io/blog-pages/machinelearning/five/11-01.png =360x","https://mister-hope.github.io/blog-pages/machinelearning/five/11-02.png =360x","https://mister-hope.github.io/blog-pages/machinelearning/five/11-03.png =560x","https://mister-hope.github.io/blog-pages/machinelearning/five/11-03.png =560x","https://mister-hope.github.io/blog-pages/machinelearning/five/11-04.png =560x","https://mister-hope.github.io/blog-pages/machinelearning/five/11-05.png =560x","https://mister-hope.github.io/blog-pages/machinelearning/five/11-06.png =560x","https://mister-hope.github.io/blog-pages/machinelearning/five/11-04.png =560x","https://mister-hope.github.io/blog-pages/machinelearning/five/11-07.png =560x","https://mister-hope.github.io/blog-pages/machinelearning/five/11-08.png =560x","https://mister-hope.github.io/blog-pages/machinelearning/five/11-09.png =560x","https://mister-hope.github.io/blog-pages/machinelearning/five/11-10.png =560x","https://mister-hope.github.io/blog-pages/machinelearning/five/11-11.png =560x","https://mister-hope.github.io/blog-pages/machinelearning/five/11-12.png =560x","https://mister-hope.github.io/blog-pages/machinelearning/five/11-13.png =560x","https://mister-hope.github.io/blog-pages/machinelearning/five/11-12.png =560x","https://mister-hope.github.io/blog-pages/machinelearning/five/11-14.png =560x","https://mister-hope.github.io/blog-pages/machinelearning/five/11-15.png =560x","https://mister-hope.github.io/blog-pages/machinelearning/five/11-16.png =560x","https://mister-hope.github.io/blog-pages/machinelearning/five/11-17.png =560x","https://mister-hope.github.io/blog-pages/machinelearning/five/11-18.png =560x"],"datePublished":"2024-08-28T00:00:00.000Z","dateModified":"2024-08-28T14:28:20.000Z","author":[{"@type":"Person","name":"AOSAI"}]}</script><title>3-3 强化学习 | 青裁的博客</title><meta name="description" content="强化学习（Reinforcement Learning） 1. 强化学习概述 在机器学习中，强化学习与其说是一类算法，不如说是一种思想，就和 贪心、动态规划、分治、回溯 这些经典的解决思路一样。虽然目前尚未在商业领域中得到广泛应用，但它也是机器学习的支柱之一。 我们还是从一个例子开始，图 11.1 是斯坦福大学自主研发的遥感直升机，重 32 磅。与其他...">
    <link rel="preload" href="/blog-pages/assets/style-ChcH9QVm.css" as="style"><link rel="stylesheet" href="/blog-pages/assets/style-ChcH9QVm.css">
    <link rel="modulepreload" href="/blog-pages/assets/app-CH05aeyc.js"><link rel="modulepreload" href="/blog-pages/assets/11_reinforcement_learning.html-BUyOjDiY.js"><link rel="modulepreload" href="/blog-pages/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/blog-pages/assets/index.html-CM-_Du5R.js" as="script"><link rel="prefetch" href="/blog-pages/assets/disable.html-CPKt6g_o.js" as="script"><link rel="prefetch" href="/blog-pages/assets/encrypt.html-CP64n5eQ.js" as="script"><link rel="prefetch" href="/blog-pages/assets/layout.html-D7vYLCVY.js" as="script"><link rel="prefetch" href="/blog-pages/assets/markdown.html-D26m9E54.js" as="script"><link rel="prefetch" href="/blog-pages/assets/page.html-BEVMPRmq.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-BCXAj-QM.js" as="script"><link rel="prefetch" href="/blog-pages/assets/cherry.html-CkE9Lo-3.js" as="script"><link rel="prefetch" href="/blog-pages/assets/dragonfruit.html-k9uQKkD1.js" as="script"><link rel="prefetch" href="/blog-pages/assets/strawberry.html-CPa5dFZn.js" as="script"><link rel="prefetch" href="/blog-pages/assets/tomato.html-BRkD9429.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-DoFgjsgp.js" as="script"><link rel="prefetch" href="/blog-pages/assets/1.html-UCYUDBb2.js" as="script"><link rel="prefetch" href="/blog-pages/assets/2.html-h1R-j8xA.js" as="script"><link rel="prefetch" href="/blog-pages/assets/3.html-BpLBlAWE.js" as="script"><link rel="prefetch" href="/blog-pages/assets/4.html-CG6e7sPY.js" as="script"><link rel="prefetch" href="/blog-pages/assets/1.html-G45bXKIo.js" as="script"><link rel="prefetch" href="/blog-pages/assets/2.html-BQD7mkJ-.js" as="script"><link rel="prefetch" href="/blog-pages/assets/3.html-BgEcG7JF.js" as="script"><link rel="prefetch" href="/blog-pages/assets/4.html-BkG4XOMc.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-S8NVGnzx.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-CleEgZIq.js" as="script"><link rel="prefetch" href="/blog-pages/assets/01_fargoing.html-DDz5H7n6.js" as="script"><link rel="prefetch" href="/blog-pages/assets/02_sichuan.html-C-7wook4.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-Be-PwI-X.js" as="script"><link rel="prefetch" href="/blog-pages/assets/01.html-qSCtWpRI.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-CCP1RVp3.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-DX4rRa3K.js" as="script"><link rel="prefetch" href="/blog-pages/assets/02_linear_regression.html-BgnTlc_T.js" as="script"><link rel="prefetch" href="/blog-pages/assets/03_linear_regression.html-D5UjEQNw.js" as="script"><link rel="prefetch" href="/blog-pages/assets/04_classification.html-rkkjgJ5j.js" as="script"><link rel="prefetch" href="/blog-pages/assets/05_deep_learning.html-BKE-cIXF.js" as="script"><link rel="prefetch" href="/blog-pages/assets/06_tensorflow.html-C6-ap8zw.js" as="script"><link rel="prefetch" href="/blog-pages/assets/07_model_evaluation.html-B3RPlCVH.js" as="script"><link rel="prefetch" href="/blog-pages/assets/08_decision_tree.html-Cu5UYSDV.js" as="script"><link rel="prefetch" href="/blog-pages/assets/09_unsupervised_learning.html-ugM8icHR.js" as="script"><link rel="prefetch" href="/blog-pages/assets/10_recommendation_system.html-CSwl-duD.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-DECXjF33.js" as="script"><link rel="prefetch" href="/blog-pages/assets/01.html-DYVEGu6z.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-Dovvm0lH.js" as="script"><link rel="prefetch" href="/blog-pages/assets/01.html-RsTecOfy.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-Dex3v3T1.js" as="script"><link rel="prefetch" href="/blog-pages/assets/01_base.html-DUKVIMxW.js" as="script"><link rel="prefetch" href="/blog-pages/assets/02_project1.html-Ccn8MrpU.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-DEI-aI5L.js" as="script"><link rel="prefetch" href="/blog-pages/assets/01_recommend_model.html-B0ySzQI7.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-BLE89CqR.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-C9NqB5rf.js" as="script"><link rel="prefetch" href="/blog-pages/assets/01_compress_photo.html-Dbpyf09_.js" as="script"><link rel="prefetch" href="/blog-pages/assets/02_file_packaging.html-6PV-Xydy.js" as="script"><link rel="prefetch" href="/blog-pages/assets/03_pyqt5_recording.html-CqBAru2J.js" as="script"><link rel="prefetch" href="/blog-pages/assets/04_spider_for_ticket.html-DyCHMUjv.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-OparkUpZ.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-CWIwhSh4.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-DVtd6pll.js" as="script"><link rel="prefetch" href="/blog-pages/assets/404.html-BsKWPMmJ.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-BRMvZ0Ll.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-tWZpuTrU.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-D90bFmxr.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-DqRPj--6.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-D7_mBELA.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-BDtR3x3e.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-ftNcK0d-.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-BikQiGUT.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-nt-vZbJO.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-DKOGH_y_.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-IK2TdfhV.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html--TOjr6g4.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-D0Ib1QSj.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-B4dq7NG_.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-4ER5OxdC.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-CQ2CEfG8.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-DZadTeIz.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-D3i_jQOs.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-Hj5LUVFx.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-BXgxVcsT.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-CQH-aOo3.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-DOtV51Fn.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-CWZuOZp6.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-DbVzWGP1.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-CzKA9ZQV.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-BVDRYuBL.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-_hrAIzP7.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-CEmIPmgX.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-DmC1ts_n.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-Vhu-cRC6.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-foGaHCBQ.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-BOILAONN.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-C5YoCZRY.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-Bn9Bfsq6.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-6nLgtfEh.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-XcsOz3yt.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-CiD-wsng.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-DHrzAxbt.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-4UV4l_ip.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-Vokv3-Zg.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-CkZ8nsRs.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-BzrB1X5U.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-DyEmxGRD.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-CMXEaJUG.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-Cw2AnjIJ.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-CSjmCj9d.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-D6Cfgbgm.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-CqMY5xds.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-BvSkESQN.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-DP3gd-oE.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-Dx3qC1L8.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-AvgKz32o.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-DL0Sp0w-.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-jgDNeDf8.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-Dg8TGTeK.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-Di4-3yio.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-qvMPjqCA.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-B6-KbPl9.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-dP3-8QKs.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-NC0STgEF.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-DKGFJS7X.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-CWY0j3cn.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-COyu5rOG.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-Dft4fa9W.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-CcrE5-PT.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-BLAysKiR.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-C6nMWlnC.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-Cdhub77P.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-Baz58OQN.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-BaWK0uc2.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-D0Cqn1bm.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-Cz9sWoN9.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-Bdi6fkv9.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-DpDWTb3C.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-BW5_GDRT.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-BQpCtJoH.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-Bu6sE2qX.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-D_uuS58B.js" as="script"><link rel="prefetch" href="/blog-pages/assets/index.html-Bf6Iyqfr.js" as="script"><link rel="prefetch" href="/blog-pages/assets/photoswipe.esm-GXRgw7eJ.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container external-link-icon has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/blog-pages/zh/"><img class="vp-nav-logo" src="/blog-pages/blog_logo.svg" alt><!----><span class="vp-site-name hide-in-pad">青裁的博客</span></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/blog-pages/zh/" aria-label="博客主页"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span><!--]-->博客主页<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="软件开发"><!--[--><!---->软件开发<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-pages/zh/software/pyqt5/" aria-label="PyQt5"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-sitemap" style=""></span><!--]-->PyQt5<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-pages/zh/software/front_end/" aria-label="前端开发"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-sitemap" style=""></span><!--]-->前端开发<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-pages/zh/software/back_end/" aria-label="后端开发"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-sitemap" style=""></span><!--]-->后端开发<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-pages/zh/software/desktop_app/" aria-label="桌面应用"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-sitemap" style=""></span><!--]-->桌面应用<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="人工智能"><!--[--><!---->人工智能<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/blog-pages/zh/intelligence/MachineLearning/" aria-label="机器学习"><!---->机器学习<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-pages/zh/intelligence/Numpy/" aria-label="Numpy"><!---->Numpy<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-pages/zh/intelligence/Matplotlib/" aria-label="Matplotlib"><!---->Matplotlib<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-pages/zh/intelligence/PyTorch/" aria-label="PyTorch"><!---->PyTorch<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-pages/zh/intelligence/recommendationSystem/" aria-label="推荐系统"><!---->推荐系统<!----></a></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="玩出点名堂"><!--[--><!---->玩出点名堂<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-pages/zh/dobetter/mahjong/" aria-label="麻将秘籍"><!---->麻将秘籍<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-pages/zh/dobetter/musictheroy/" aria-label="吉他乐理"><!---->吉他乐理<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-pages/zh/dobetter/photograph/" aria-label="摄影摄像"><!---->摄影摄像<!----></a></li></ul></button></div></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><div class="vp-nav-item"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="选择语言"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" name="i18n" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/blog-pages/" aria-label="English"><!---->English<!----></a></li><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/blog-pages/zh/intelligence/MachineLearning/11_reinforcement_learning.html" aria-label="简体中文"><!---->简体中文<!----></a></li></ul></button></div></div><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/vuepress-theme-hope/vuepress-theme-hope" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/blog-pages/zh/intelligence/MachineLearning/" aria-label="0-0 机器学习目录与概述"><!---->0-0 机器学习目录与概述<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/blog-pages/zh/intelligence/MachineLearning/02_linear_regression.html" aria-label="1-1 一元线性回归"><!---->1-1 一元线性回归<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/blog-pages/zh/intelligence/MachineLearning/03_linear_regression.html" aria-label="1-2 多元线性回归"><!---->1-2 多元线性回归<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/blog-pages/zh/intelligence/MachineLearning/04_classification.html" aria-label="1-3 分类问题"><!---->1-3 分类问题<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/blog-pages/zh/intelligence/MachineLearning/05_deep_learning.html" aria-label="2-1 神经网络初探"><!---->2-1 神经网络初探<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/blog-pages/zh/intelligence/MachineLearning/06_tensorflow.html" aria-label="2-2 神经网络进阶"><!---->2-2 神经网络进阶<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/blog-pages/zh/intelligence/MachineLearning/07_model_evaluation.html" aria-label="2-3 模型评估"><!---->2-3 模型评估<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/blog-pages/zh/intelligence/MachineLearning/08_decision_tree.html" aria-label="2-4 决策树模型"><!---->2-4 决策树模型<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/blog-pages/zh/intelligence/MachineLearning/09_unsupervised_learning.html" aria-label="3-1 无监督学习"><!---->3-1 无监督学习<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/blog-pages/zh/intelligence/MachineLearning/10_recommendation_system.html" aria-label="3-2 推荐系统"><!---->3-2 推荐系统<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/blog-pages/zh/intelligence/MachineLearning/11_reinforcement_learning.html" aria-label="3-3 强化学习"><!---->3-3 强化学习<!----></a></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->3-3 强化学习</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">AOSAI</span></span><span property="author" content="AOSAI"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2024-08-28T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 23 分钟</span><meta property="timeRequired" content="PT23M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color6 clickable" role="navigation">机器学习</span><!--]--><meta property="articleSection" content="机器学习"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color4 clickable" role="navigation">强化学习</span><!--]--><meta property="keywords" content="强化学习"></span></div><hr></div><div class="vp-toc-placeholder"><aside id="toc"><!----><div class="vp-toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon" name="print"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_1-强化学习概述">1. 强化学习概述</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-1-什么是强化学习">1.1 什么是强化学习</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-2-形式-火星探测器">1.2 形式（火星探测器）</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-3-回报-火星探测器">1.3 回报（火星探测器）</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-4-决策-火星探测器">1.4 决策（火星探测器）</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-5-回顾总结">1.5 回顾总结</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_2-状态-动作价值函数">2. 状态-动作价值函数</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-1-代码示例">2.1 代码示例</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-2-贝尔曼方程-bellman-equation">2.2 贝尔曼方程（Bellman Equation）</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-3-随机环境">2.3 随机环境</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_3-连续的状态空间">3. 连续的状态空间</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-1-登月器">3.1 登月器</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-2-强化学习中的神经网络">3.2 强化学习中的神经网络</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-3-构建训练集">3.3 构建训练集</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-4-deep-q-network-dqn">3.4 Deep Q-Network（DQN）</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_4-算法改进">4. 算法改进</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_4-1-神经网络架构改进">4.1 神经网络架构改进</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_4-2-ε-贪婪策略-epsilon-greedy-policy">4.2 ε-贪婪策略（Epsilon-greedy policy）</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_4-3-超参数的敏感性">4.3 超参数的敏感性</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_4-4-小批量处理-mini-batch">4.4 小批量处理（mini-batch）</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_4-5-软更新">4.5 软更新</a></li><!----><!--]--></ul></li><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!----></aside></div><!----><div class="theme-hope-content"><p>强化学习（Reinforcement Learning）</p><h2 id="_1-强化学习概述" tabindex="-1"><a class="header-anchor" href="#_1-强化学习概述"><span>1. 强化学习概述</span></a></h2><p>在机器学习中，强化学习与其说是一类算法，不如说是一种思想，就和 <strong>贪心、动态规划、分治、回溯</strong> 这些经典的解决思路一样。虽然目前尚未在商业领域中得到广泛应用，但它也是机器学习的支柱之一。</p><p>我们还是从一个例子开始，图 11.1 是斯坦福大学自主研发的遥感直升机，重 32 磅。与其他遥感直升机一样，它配备了机载计算机、GPS、加速度计、陀螺仪和磁罗盘，因此它可以随时非常准确的知道自己的位置。</p><div class="layout"><figure><img src="/blog-pages/machinelearning/five/11-01.png" alt="11.1 强化学习-遥感直升机1" width="360" tabindex="0" loading="lazy"><figcaption>11.1 强化学习-遥感直升机1</figcaption></figure><figure><img src="/blog-pages/machinelearning/five/11-02.png" alt="11.2 强化学习-遥感直升机2" width="360" tabindex="0" loading="lazy"><figcaption>11.2 强化学习-遥感直升机2</figcaption></figure></div><p>遥感直升机的正常操作，就像 90 年代用手柄打卡带游戏一样，通过操作两个摇杆，以及不同的功能按钮，保持直升机在空中的平衡和飞行。</p><p>图 11.2 是吴恩达教授驾驶摇杆直升机的图像，仔细观察会发现，这个直升机它在倒着飞，有点像空中杂技。没错，它就是用强化学习做到的。如果你有兴趣看更多的视频，可以 <a href="http://heli.stanford.edu" target="_blank" rel="noopener noreferrer">点击此处</a>。</p><p>那么问题来了，如果给你一架摇杆直升机的密钥，让你来编写一个程序去自主驾驶它，你会怎么做？</p><h3 id="_1-1-什么是强化学习" tabindex="-1"><a class="header-anchor" href="#_1-1-什么是强化学习"><span>1.1 什么是强化学习</span></a></h3><p>假设我们给定一个任务：通过直升机的位置来决定如何移动驾驶杆。</p><p>我们将直升机的位置、方向、速度等称为状态 s。目标任务是找到一个函数，将直升机的状态映射到动作 a，即将两个操作杆推多远，以保证直升机在空中飞行时保持平衡不会坠毁。</p><p>这个任务也许能通过监督学习完成。比如我们有大量的状态观察结果，并且有一位专业的人类飞行员告诉我们应该采取的最佳行动是什么。然后你就可以使用监督学习训练神经网络，以直接学习 x（s）到标签 y（动作 a）的映射。</p><p>但事实证明，当直升机在空中移动时，“应该采取什么正确的行动”这个问题是很模糊的。比如向左倾斜时是一点还是很大？或者增加直升机压力是稍微还是很多？得到 x 和理想动作 y 的数据集是非常困难的。</p><p>这就是为什么对于很多控制机器人的任务，监督学习方法效果不佳，从而改为使用强化学习。<strong>强化学习的一个关键输入，叫做奖励（函数），它会告诉算法什么时候做的好，什么时候做的不好。</strong></p><p>对于奖励函数，在吴恩达教授看来就像是训练小狗。如何让小狗表现良好呢？你不能向小狗展示太多东西，相反，你只是让它做自己的事情，如果做的好，就鼓励夸夸，如果做了坏事，就凶它骂它。然后希望它自己学习如何做更多好的事情，做更少坏的事情。</p><p>强化学习算法也是这样，做的好的时候夸你，做的不好的时候骂你。比如直升机飞的好的时候，奖励它多飞 1 秒（+1）；飞的不好的时候，给一个负奖励，少飞 1 秒（-1）；如果坠毁，给一个非常大的负奖励，比如（-1000）。</p><h3 id="_1-2-形式-火星探测器" tabindex="-1"><a class="header-anchor" href="#_1-2-形式-火星探测器"><span>1.2 形式（火星探测器）</span></a></h3><figure><img src="/blog-pages/machinelearning/five/11-03.png" alt="11.3 火星探测器1" width="560" tabindex="0" loading="lazy"><figcaption>11.3 火星探测器1</figcaption></figure><p>在这个简化的例子中，探测器有 6 个可能会移动的位置（状态）。假设探测器一开始在状态 4，它可以去不同的地方用它的传感器（探头、雷达、光谱仪等等）来分析火星上不同地方的岩石，或者拍摄有趣的照片供科学家们观看。</p><p>状态 1 和状态 6 都有非常有趣的地质结构，科学家们希望探测器对其采样，但状态 1 的有趣程度为 100 分，状态 6 的有趣程度为 40 分。其余的状态奖励为 0。</p><p>在每一步的决策中，探测器都可以选择向左走或者向右走。我们可以模拟几种情况来做说明：</p><ul><li>一直往左走，奖励为 [0, 0, 0, 100]</li><li>一直往右走，奖励为 [0, 0, 40]</li><li>先往右走一次，再往左走，奖励为 [0, 0, 0, 0, 0, 100]</li></ul><p>第三种情况很明显不太好，但是它也有可能会发生。</p><p>总而言之，每一个阶段，探测机器人都会处于某种状态（称为 s），它可以选择一个动作（称为 a），并且它还有一些从状态中获得的奖励（称为 R(s)），以及因为动作而产生的新的状态（称为 s&#39;）。</p><p>强化学习的核心要素就是这四件事：<strong>状态、动作、奖励、下一个状态</strong>，记录为：（s, a, R(s), s&#39;）。比如探测器从状态 4 往左走一次：（4, left, 0, 3）。</p><p>对于这个应用程序，假设它进入状态 1 或 6 时，这一天就结束了。这种情况在强化学习中被称为<strong>终端状态</strong>，意味着一旦到达终端状态之一后，获得奖励后就结束后续的动作。</p><h3 id="_1-3-回报-火星探测器" tabindex="-1"><a class="header-anchor" href="#_1-3-回报-火星探测器"><span>1.3 回报（火星探测器）</span></a></h3><p>回报这个概念，是强化学习中如何实施动作，做决策的关键。</p><p>做个有意思的类比：假设你站在分叉路口，往左走 5 分钟可以捡到一张 5 美元的钞票，往右走 30 分钟可以捡到一张 10 美元的钞票，你会往哪里走？</p><p>虽然 10 美元看起来比 5 美元好多了，但是如果要你花 30 分钟去拿那张 10 美元，也许你会觉得没有 5 美元来的更方便。</p><p>所以，在这个例子中，回报的概念抓住了你“更快获得奖励”可能比“需要更长时间才能获得奖励”更有吸引力。</p><p><strong>回报被定义为这些奖励的总和，但其中需要一个叫做“折扣因子（Gamma）”的东西加权。</strong> 还是火星探测器的图例：</p><figure><img src="/blog-pages/machinelearning/five/11-03.png" alt="11.3 火星探测器1" width="560" tabindex="0" loading="lazy"><figcaption>11.3 火星探测器1</figcaption></figure><p>假设折扣因子为 0.9，我们从状态 4 一直向左移动到状态 1，它的回报是：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>R</mi><mi>e</mi><mi>t</mi><mi>u</mi><mi>r</mi><mi>n</mi><mo>=</mo><mn>0</mn><mo>+</mo><mo stretchy="false">(</mo><mn>0.9</mn><mo stretchy="false">)</mo><mo>⋅</mo><mn>0</mn><mo>+</mo><mo stretchy="false">(</mo><mn>0.9</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>⋅</mo><mn>0</mn><mo>+</mo><mo stretchy="false">(</mo><mn>0.9</mn><msup><mo stretchy="false">)</mo><mn>3</mn></msup><mo>⋅</mo><mn>100</mn><mo>=</mo><mn>72.9</mn></mrow><annotation encoding="application/x-tex"> Return=0+(0.9)\cdot{0}+(0.9)^{2}\cdot{0}+(0.9)^{3}\cdot{100}=72.9 </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0.9</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord">0</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0.9</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord">0</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0.9</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord"><span class="mord">100</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">72.9</span></span></span></span></span></p><p>我们可以看到，折扣因子 Gamma 是指数型增长，越到后面越小。吴恩达教授的解释很有趣，他说：Gamma 的作用是让强化学习有点不耐烦。这样它就会往奖励越大的、越靠近的状态上靠。</p><p>用符号归纳一下回报的函数，它可以写为：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>R</mi><mi>e</mi><mi>t</mi><mi>u</mi><mi>r</mi><mi>n</mi><mo>=</mo><msub><mi>R</mi><mn>1</mn></msub><mo>+</mo><mi>γ</mi><msub><mi>R</mi><mn>2</mn></msub><mo>+</mo><msup><mi>γ</mi><mn>2</mn></msup><msub><mi>R</mi><mn>3</mn></msub><mo>+</mo><mo>⋯</mo></mrow><annotation encoding="application/x-tex"> Return=R_{1}+\gamma{R_{2}}+\gamma^{2}{R_{3}}+\cdots </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0585em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.313em;"></span><span class="minner">⋯</span></span></span></span></span></p><p>在许多强化学习算法中，折扣因子的选择是非常接近 1 的数字，比如 0.9，0.99，甚至 0.999。但是为了能从另一个角度，更好的理解回报的原理，这里 Gamma 选择了 0.5。</p><figure><img src="/blog-pages/machinelearning/five/11-04.png" alt="11.4 火星探测器2" width="560" tabindex="0" loading="lazy"><figcaption>11.4 火星探测器2</figcaption></figure><p>图中的三行数据，每一行里红色的数字表示回报，黄色的箭头表示在该状态下往哪边走，黑色的数字代表奖励。三种不同的移动模式所带来的回报，差别是很明显的。</p><h3 id="_1-4-决策-火星探测器" tabindex="-1"><a class="header-anchor" href="#_1-4-决策-火星探测器"><span>1.4 决策（火星探测器）</span></a></h3><p>如同前几个小节所讲，强化学习中可以采取多种不同的方式，去决定下一个动作该做什么，比如在火星探测器中：</p><ol><li>总是追求更接近的奖励。靠近左边就往左边走，靠近右边就往右边走。</li><li>总是追求更大的奖励。状态 1 奖励最大，所以总是往左走。</li><li>总是追求更小的奖励。总是往右走，虽然看起来不是一个好主意，但也是一种选择。</li><li>往更大的奖励走，除非距离较小的奖励仅一步之遥。状态 234 往左走，状态 5 往右走。</li></ol><figure><img src="/blog-pages/machinelearning/five/11-05.png" alt="11.5 火星探测器3" width="560" tabindex="0" loading="lazy"><figcaption>11.5 火星探测器3</figcaption></figure><p>在强化学习中，我们的目标是提出一个称为 策略 Pi 的函数，将任何状态 s 作为输入并将其映射到它希望我们采取的某个动作 a。比如策略 Pi 选择了第 4 种方式，那么探测机器人就会按照第 4 种方式去移动。</p><p>强化学习的目标是找到一个策略 Pi，告诉你在不同的状态下，采取什么行动可以获得最大化的回报。</p><h3 id="_1-5-回顾总结" tabindex="-1"><a class="header-anchor" href="#_1-5-回顾总结"><span>1.5 回顾总结</span></a></h3><p>我们用 6 种状态的火星探测器示例初步讲解了强化学习的形式，让我们快速回顾一下关键概念，并了解如何将这组概念应用于其他的程序。</p><figure><img src="/blog-pages/machinelearning/five/11-06.png" alt="11.6 回顾小结" width="560" tabindex="0" loading="lazy"><figcaption>11.6 回顾小结</figcaption></figure><p>火星探测器和遥感直升机已经在前面说过了，第三个是国际象棋。假设你想使用强化学习来学习下棋：</p><ul><li><strong>状态</strong>：棋盘上所有棋子的位置（简化版）。</li><li><strong>动作</strong>：游戏中合法的移动。</li><li><strong>奖励</strong>：常见方式为，赢了奖励+1，输了负奖励-1，零奖励可能与游戏有关。</li><li><strong>折扣因子</strong>：国际象棋通常 Gamma 为接近 1 的数字，比如 0.99。</li><li><strong>回报</strong>：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mn>1</mn></msub><mo>+</mo><mi>γ</mi><msub><mi>R</mi><mn>2</mn></msub><mo>+</mo><msup><mi>γ</mi><mn>2</mn></msup><msub><mi>R</mi><mn>3</mn></msub><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">R_{1}+\gamma{R_{2}}+\gamma^{2}{R_{3}} ...</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mord">...</span></span></span></span></li><li><strong>决策</strong>：目标棋子被赋予了一个棋盘位置，使用策略 Pi 选择一个好的动作。</li></ul><p>这种强化学习应用程序的形式实际上有一个名字，叫做：<strong>马尔可夫决策过程（Markov Decision Process，MDP）</strong>。它是指：未来仅取决于当前的状态，而不是取决于到达当前状态之前可能发生的任何事情。</p><h2 id="_2-状态-动作价值函数" tabindex="-1"><a class="header-anchor" href="#_2-状态-动作价值函数"><span>2. 状态-动作价值函数</span></a></h2><p>状态-动作价值函数（State-action value function）的目的是为了寻找当前状态下，回报最大的动作。也就是让回报最大化，它的形式可以写为循环：</p><p>Q(s, a) = Return if you</p><ul><li>start in state s.</li><li>take action a (just once).</li><li>then behave optimally after that.</li></ul><figure><img src="/blog-pages/machinelearning/five/11-04.png" alt="11.4 火星探测器2" width="560" tabindex="0" loading="lazy"><figcaption>11.4 火星探测器2</figcaption></figure><p>这是 1.3 小节中讲回报的图，第一行是火星探测车全向左走，第二行是全向右走。我们将这两行的回报结合起来，对比大小来看，第三行其实就是最大回报的动作决策。</p><p>另外，因为这个函数总是被写作 Q 函数，或者 Q*函数（optimal Q function），所以如果你在很多文献里看到了它们，不要惊讶，它们就表示状态-动作价值函数。</p><h3 id="_2-1-代码示例" tabindex="-1"><a class="header-anchor" href="#_2-1-代码示例"><span>2.1 代码示例</span></a></h3><p>这是吴恩达教授简化的代码（<a href="/machinelearning/five/utils.py" target="_blank" rel="noopener noreferrer">utils.py 文件可以从此处打开</a>），他希望我们通过自己修改一些参数，比如更改两边的奖励数值、更改折扣因子的大小等等，看看自动策略会如何根据这些不同的值而变化。</p><div class="vp-tabs"><div class="vp-tabs-nav" role="tablist"><button type="button" class="vp-tab-nav active" role="tab" aria-controls="tab-264-0" aria-selected="true">简化版代码</button><button type="button" class="vp-tab-nav" role="tab" aria-controls="tab-264-1" aria-selected="false">运行结果</button></div><!--[--><div class="vp-tab active" id="tab-264-0" role="tabpanel" aria-expanded="true"><div class="vp-tab-title">简化版代码</div><!--[--><div class="language-py line-numbers-mode" data-highlighter="shiki" data-ext="py" data-title="py" style="--shiki-light:#24292e;--shiki-dark:#abb2bf;--shiki-light-bg:#fff;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes github-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> numpy </span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> np</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;"> utils </span><span style="--shiki-light:#D73A49;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;"> *</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">num_states </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 6</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">num_actions </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 2</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">terminal_left_reward </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 100</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">terminal_right_reward </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 40</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">each_step_reward </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 0</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;"># Discount factor</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">gamma </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 0.5</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#7F848E;--shiki-light-font-style:inherit;--shiki-dark-font-style:italic;">#probability of going in the wrong direction</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">misstep_prob </span><span style="--shiki-light:#D73A49;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#D19A66;"> 0</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#61AFEF;">generate_visualization</span><span style="--shiki-light:#24292E;--shiki-dark:#ABB2BF;">(terminal_left_reward, terminal_right_reward, each_step_reward, gamma, misstep_prob)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><!--]--></div><div class="vp-tab" id="tab-264-1" role="tabpanel" aria-expanded="false"><div class="vp-tab-title">运行结果</div><!--[--><figure><img src="/blog-pages/machinelearning/five/11-07.png" alt="11.7 状态-动作价值函数" width="560" tabindex="0" loading="lazy"><figcaption>11.7 状态-动作价值函数</figcaption></figure><!--]--></div><!--]--></div><p>有的同学可能看了运行结果会问，为什么状态 2 和状态 3 向右走的回报，不是 2.5 和 5，反而是 12.5 和 6.25 呢。因为这两个状态向右走的策略是：先往右走一次，然后一直往左走。</p><p>Q 函数的目的是找寻回报最大化的动作，在状态 2 中，12.5 明显比 2.5 大，所以迂回的走法比一直向右走看起来更好，状态 3 同理。</p><p>此外，misstep_prob 这个参数详情，请看 2.3 小节，随机环境。</p><h3 id="_2-2-贝尔曼方程-bellman-equation" tabindex="-1"><a class="header-anchor" href="#_2-2-贝尔曼方程-bellman-equation"><span>2.2 贝尔曼方程（Bellman Equation）</span></a></h3><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><mi>R</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><mo>⋅</mo><mrow><mi>max</mi><mo>⁡</mo><mrow><mi>Q</mi><mo stretchy="false">(</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex"> Q(s, a)=R(s)+\gamma\cdot{\max{Q(s&#39;, a&#39;)}} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0519em;vertical-align:-0.25em;"></span><span class="mord"><span class="mop">max</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span></span></p><p>贝尔曼方程简单的来说，就是告诉我们，当前状态下该动作的回报，是由（1）当前状态的奖励，也称作即时奖励；（2）折扣因子 × 下一个状态的回报最大的动作；两个部分组成。它其实可以看作是对回报的拆分：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>R</mi><mi>e</mi><mi>t</mi><mi>u</mi><mi>r</mi><mi>n</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msub><mi>R</mi><mn>1</mn></msub><mo>+</mo><mi>γ</mi><msub><mi>R</mi><mn>2</mn></msub><mo>+</mo><msup><mi>γ</mi><mn>2</mn></msup><msub><mi>R</mi><mn>3</mn></msub><mo>+</mo><mo>⋯</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msub><mi>R</mi><mn>1</mn></msub><mo>+</mo><mi>γ</mi><mrow><mo stretchy="false">[</mo><msub><mi>R</mi><mn>2</mn></msub><mo>+</mo><mi>γ</mi><msub><mi>R</mi><mn>3</mn></msub><mo>+</mo><mo>⋯</mo><mtext> </mtext><mo stretchy="false">]</mo></mrow></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>R</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><mo>⋅</mo><mrow><mi>max</mi><mo>⁡</mo><mrow><mi>Q</mi><mo stretchy="false">(</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow></mrow></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex"> \begin{align} Return &amp;= R_{1}+\gamma{R_{2}}+\gamma^{2}{R_{3}}+\cdots \\ &amp;= R_{1}+\gamma{[R_{2}+\gamma{R_{3}}+\cdots]} \\ &amp;= R(s)+\gamma\cdot{\max{Q(s&#39;, a&#39;)}} \end{align} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.5241em;vertical-align:-2.0121em;"></span><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.5121em;"><span style="top:-4.6479em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">n</span></span></span><span style="top:-3.1479em;"><span class="pstrut" style="height:3em;"></span><span class="mord"></span></span><span style="top:-1.6479em;"><span class="pstrut" style="height:3em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.0121em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.5121em;"><span style="top:-4.6479em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="minner">⋯</span></span></span><span style="top:-3.1479em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord"><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mclose">]</span></span></span></span><span style="top:-1.6479em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mop">max</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.0121em;"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.5121em;"><span style="top:-4.5121em;"><span class="pstrut" style="height:2.8641em;"></span><span class="eqn-num"></span></span><span style="top:-3.0121em;"><span class="pstrut" style="height:2.8641em;"></span><span class="eqn-num"></span></span><span style="top:-1.5121em;"><span class="pstrut" style="height:2.8641em;"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.0121em;"><span></span></span></span></span></span></span></span></span></p><figure><img src="/blog-pages/machinelearning/five/11-08.png" alt="11.8 贝尔曼方程" width="560" tabindex="0" loading="lazy"><figcaption>11.8 贝尔曼方程</figcaption></figure><p>图 11.8 中举了两个例子，从状态 2 往右走，计算出来 12.5 就是它的最大回报；从状态 4 往左走，12.5 是它的最大回报。</p><h3 id="_2-3-随机环境" tabindex="-1"><a class="header-anchor" href="#_2-3-随机环境"><span>2.3 随机环境</span></a></h3><p>在实践中，由于刮风、偏离航线、车轮打滑等等原因，许多机器人没有办法完全按照你的要求去做，所以结果并不会总是可靠。</p><p>比如，在火星探测器向左行驶的途中，可能会遇见岩石滑坡，或者地面真的很滑，导致它滑向了错误的方向。</p><p>我们可以模拟它出现错误的概率，比如 90%的概率会正常运行，10%的概率会遭遇意外情况。比如：</p><ul><li>从状态 3 向左走，没有出错：[0, 0, 100]</li><li>从状态 3 向左走，在状态 2 时打滑了一次，回到了状态 3：[0, 0, 0, 0, 100]</li></ul><p>我们会发现，加入概率之后啊，回报就不是一个准确的公式，而是无数个公式的集合，我们需要取它的平均值，或者说是期望，来重新测定每个状态，往左或往右走的回报。</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>E</mi><mi>x</mi><mi>p</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>e</mi><mi>d</mi><mi mathvariant="normal">_</mi><mi>R</mi><mi>e</mi><mi>t</mi><mi>u</mi><mi>r</mi><mi>n</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>A</mi><mi>v</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>g</mi><mi>e</mi><mo stretchy="false">(</mo><msub><mi>R</mi><mn>1</mn></msub><mo>+</mo><mi>γ</mi><msub><mi>R</mi><mn>2</mn></msub><mo>+</mo><msup><mi>γ</mi><mn>2</mn></msup><msub><mi>R</mi><mn>3</mn></msub><mo>+</mo><mo>⋯</mo><mtext> </mtext><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr><mtr><mtd class="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>E</mi><mo stretchy="false">[</mo><msub><mi>R</mi><mn>1</mn></msub><mo>+</mo><mi>γ</mi><msub><mi>R</mi><mn>2</mn></msub><mo>+</mo><msup><mi>γ</mi><mn>2</mn></msup><msub><mi>R</mi><mn>3</mn></msub><mo>+</mo><mo>⋯</mo><mtext> </mtext><mo stretchy="false">]</mo></mrow></mstyle></mtd><mtd class="mtr-glue"></mtd><mtd class="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex"> \begin{align} Expected\_Return &amp;= Average(R_{1}+\gamma{R_{2}}+\gamma^{2}{R_{3}}+\cdots) \\ &amp;= E[R_{1}+\gamma{R_{2}}+\gamma^{2}{R_{3}}+\cdots] \end{align} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.0482em;vertical-align:-1.2741em;"></span><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7741em;"><span style="top:-3.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal">x</span><span class="mord mathnormal">p</span><span class="mord mathnormal">ec</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">n</span></span></span><span style="top:-2.3859em;"><span class="pstrut" style="height:3em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2741em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7741em;"><span style="top:-3.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal" style="margin-right:0.02778em;">er</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mclose">)</span></span></span><span style="top:-2.3859em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mclose">]</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2741em;"><span></span></span></span></span></span></span></span><span class="tag"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7741em;"><span style="top:-3.7741em;"><span class="pstrut" style="height:2.8641em;"></span><span class="eqn-num"></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:2.8641em;"></span><span class="eqn-num"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2741em;"><span></span></span></span></span></span></span></span></span></p><p>可以修改 2.1 小节中代码参数 misstep_prob，做对比观察。同理，对于贝尔曼方程，我们也需要改写为期望的形式。</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><mi>R</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><mo>⋅</mo><mrow><mi>E</mi><mo stretchy="false">[</mo><mi>max</mi><mo>⁡</mo><mrow><mi>Q</mi><mo stretchy="false">(</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow><mo stretchy="false">]</mo></mrow></mrow><annotation encoding="application/x-tex"> Q(s, a) = R(s)+\gamma\cdot{E[\max{Q(s&#39;, a&#39;)}]} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0519em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">[</span><span class="mop">max</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mclose">]</span></span></span></span></span></span></p><h2 id="_3-连续的状态空间" tabindex="-1"><a class="header-anchor" href="#_3-连续的状态空间"><span>3. 连续的状态空间</span></a></h2><p>我们使用的简化版火星探测器，是一组离散的状态，它意味着探测器只可能处于 6 个位置中的一个。</p><p>但事实上，它可以处于大量连续位置中的任何一个。比如，一条横向的 6 公里长的直线，我们以米作为单位，向左或向右走时，[0, 6000]m 以内的任何数字都是有效的。</p><figure><img src="/blog-pages/machinelearning/five/11-09.png" alt="11.9 连续的状态空间" width="560" tabindex="0" loading="lazy"><figcaption>11.9 连续的状态空间</figcaption></figure><p>我们再举一个例子，比如正在行驶的卡车（玩具车），它需要考虑的就不只是一个状态了，比如，前后方向的位置 x，左右方向的位置 y，卡车行驶的方向 θ，以及前后方向的速度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>˙</mo></mover></mrow><annotation encoding="application/x-tex">\dot{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6679em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">˙</span></span></span></span></span></span></span></span></span></span>，左右方向的速度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>y</mi><mo>˙</mo></mover></mrow><annotation encoding="application/x-tex">\dot{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8623em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0833em;"><span class="mord">˙</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span>，行驶方向/角度变化的速度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mi>o</mi><mi>t</mi><mi>θ</mi></mrow><annotation encoding="application/x-tex">dot{\theta}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">o</span><span class="mord mathnormal">t</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span></span>。</p><p>所以卡车的状态将包含由这 6 个符号组成的向量：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>=</mo><mo stretchy="false">[</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo separator="true">,</mo><mi>θ</mi><mo separator="true">,</mo><mover accent="true"><mi>x</mi><mo>˙</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>y</mi><mo>˙</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>θ</mi><mo>˙</mo></mover><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">s=[x, y, \theta, \dot{x}, \dot{y}, \dot{\theta}]^{T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1813em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">˙</span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0833em;"><span class="mord">˙</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9313em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0556em;"><span class="mord">˙</span></span></span></span></span></span></span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span>，并且这些符号中的任何一个，都可以采用有效范围内的任何值。比如方向/角度的范围为 0 到 360°。</p><h3 id="_3-1-登月器" tabindex="-1"><a class="header-anchor" href="#_3-1-登月器"><span>3.1 登月器</span></a></h3><figure><img src="/blog-pages/machinelearning/five/11-10.png" alt="11.10 登月器" width="560" tabindex="0" loading="lazy"><figcaption>11.10 登月器</figcaption></figure><p>这是一个很有意思的模拟月球着陆的程序，每个时间点你可以有四种操作：</p><ol><li>什么都不做，让惯性和重力将着陆器拉向月球表面。</li><li>启动左侧推进器，将着陆器推向右边移动。</li><li>启动右侧推进器，将着陆器推向左边移动。</li><li>启动底部的主推进器，减缓下降的速度。</li></ol><p>你的任务就是随着时间的推移，不断地选择行动，让着陆器安全的降落在两个黄旗中间的位置。那么它的状态向量都包含些什么呢？</p><ul><li>x 和 y 表示在水平方向和垂直方向的位置</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>˙</mo></mover><mtext>和</mtext><mover accent="true"><mi>y</mi><mo>˙</mo></mover></mrow><annotation encoding="application/x-tex">\dot{x}和\dot{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">˙</span></span></span></span></span></span></span><span class="mord cjk_fallback">和</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0833em;"><span class="mord">˙</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span> 表示在横轴和纵轴上的移动速度</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> 表示着陆器的角度，也就是机身的倾斜程度</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>˙</mo></mover></mrow><annotation encoding="application/x-tex">\dot{\theta}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9313em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9313em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0556em;"><span class="mord">˙</span></span></span></span></span></span></span></span></span></span> 表示倾斜的速度，或者说角速度</li><li>l 和 r 是两个布尔类型的变量，对应：左腿是否着地、右腿是否着地</li></ul><p>它的奖励函数也很有趣，之前的火星探测器，只有两个状态存在奖励，而这次的着陆器有 7 种奖励，并且包括负奖励：</p><figure><img src="/blog-pages/machinelearning/five/11-11.png" alt="11.11 登月器的奖励函数" width="560" tabindex="0" loading="lazy"><figcaption>11.11 登月器的奖励函数</figcaption></figure><ol><li>假设两根黄旗中间有一个垫子，着陆器正在设法降落在上面，我们根据降落途中的飞行情况，给 100~140 的奖励；</li><li>并且有一个额外的奖励，离垫子中心越近，奖励越高，离垫子中心越远，奖励越低；</li><li>如果坠毁，奖励-100；</li><li>软着陆成功，奖励+100；</li><li>每条腿落地，都会奖励+10；</li><li>假设我们鼓励它节省燃料，所以每次启动主引擎（主推进器）时，奖励-0.3；</li><li>每次触发左侧或右侧推进器时，奖励-0.03。</li></ol><p>这是一个中等复杂程度的奖励函数，设计者对真正你想要的行为进行了一些思考，并将其编入奖励函数中，激励更多你想要的行为。</p><p>当你自己构建一个强化学习应用程序时，通常你会花些心思来准确的指定你想要什么，你不想要什么，以及将其编入奖励函数。</p><p>总结一下，着陆器程序的任务是：在给定状态向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>=</mo><mo stretchy="false">[</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo separator="true">,</mo><mover accent="true"><mi>x</mi><mo>˙</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>y</mi><mo>˙</mo></mover><mo separator="true">,</mo><mi>θ</mi><mo separator="true">,</mo><mover accent="true"><mi>θ</mi><mo>˙</mo></mover><mo separator="true">,</mo><mi>l</mi><mo separator="true">,</mo><mi>r</mi><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">s=[x, y, \dot{x}, \dot{y}, \theta, \dot{\theta}, l, r]^{T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1813em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">˙</span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0833em;"><span class="mord">˙</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9313em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0556em;"><span class="mord">˙</span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span> 的情况下，让决策 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span> 选择一个最佳的动作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>=</mo><mi>π</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">a=\pi(s)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span>，使得回报最大化，折扣因子选定为 Gamma=0.985。</p><h3 id="_3-2-强化学习中的神经网络" tabindex="-1"><a class="header-anchor" href="#_3-2-强化学习中的神经网络"><span>3.2 强化学习中的神经网络</span></a></h3><p>用强化学习来解决登月器或者其它问题的一个关键思想是，我们要训练一个神经网络来计算或近似 state，action 的状态动作价值函数 Q。这反过来又会让我们选择一个好的行动。</p><figure><img src="/blog-pages/machinelearning/five/11-12.png" alt="11.12 强化学习中的神经网络" width="560" tabindex="0" loading="lazy"><figcaption>11.12 强化学习中的神经网络</figcaption></figure><p>神经网络的输入包含了所有的状态和动作，状态向量已经写过了：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>=</mo><mo stretchy="false">[</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo separator="true">,</mo><mover accent="true"><mi>x</mi><mo>˙</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>y</mi><mo>˙</mo></mover><mo separator="true">,</mo><mi>θ</mi><mo separator="true">,</mo><mover accent="true"><mi>θ</mi><mo>˙</mo></mover><mo separator="true">,</mo><mi>l</mi><mo separator="true">,</mo><mi>r</mi><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">s=[x, y, \dot{x}, \dot{y}, \theta, \dot{\theta}, l, r]^{T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1813em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">˙</span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0833em;"><span class="mord">˙</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9313em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0556em;"><span class="mord">˙</span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span>；4 个动作我们可以通过 one-hot 进行编码：</p><ul><li>nothing，什么都不做，[1, 0, 0, 0]</li><li>left，启动左侧推进器，[0, 1, 0, 0]</li><li>main，启动主推进器，[0, 0, 1, 0]</li><li>right，启动右侧推进器，[0, 0, 0, 1]</li></ul><p>所以这个由 12 个数字组成的列表或者说向量（8 个状态，4 个动作），我们将其写作神经网络的输入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>⃗</mo></mover></mrow><annotation encoding="application/x-tex">\vec{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.714em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2077em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em;" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span></span></span></span></span></span></span>。</p><p>需要注意的是，我们并不是输入状态就直接让它输出动作（纯粹的监督学习），而是让它输出 Q 函数。神经网络在这里只是强化学习的一个部分。</p><p>对于 Q 函数而言，这种方式的效果很好。那么到这里，问题就变成了：如何训练一个神经网络来输出 Q(s, a) 函数？</p><h3 id="_3-3-构建训练集" tabindex="-1"><a class="header-anchor" href="#_3-3-构建训练集"><span>3.3 构建训练集</span></a></h3><p>首先，该方法将使用贝尔曼方程，来创建包含大量示例（x，y）的训练集，然后使用监督学习中的神经网络做模型训练，将 state-action（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>⃗</mo></mover></mrow><annotation encoding="application/x-tex">\vec{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.714em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2077em;"><span class="overlay" style="height:0.714em;width:0.471em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.471em" height="0.714em" style="width:0.471em;" viewBox="0 0 471 714" preserveAspectRatio="xMinYMin"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span></span></span></span></span></span></span>）映射到目标值 Q(s, a)（y）。</p><figure><img src="/blog-pages/machinelearning/five/11-13.png" alt="11.13 通过贝尔曼方程构建训练集" width="560" tabindex="0" loading="lazy"><figcaption>11.13 通过贝尔曼方程构建训练集</figcaption></figure><p>我们将贝尔曼方程切分为两个部分，等式左边就是输入向量 x，等式右边就是输出 y。</p><p>问题的关键是，我们并不知道什么才是最佳的 Q 函数，能够将回报最大化的下一个状态和动作是什么我们不清楚。</p><p>没关系，我们可以取随机值，来构建一个，比如包含 1 万个数据的训练集。</p><h3 id="_3-4-deep-q-network-dqn" tabindex="-1"><a class="header-anchor" href="#_3-4-deep-q-network-dqn"><span>3.4 Deep Q-Network（DQN）</span></a></h3><p>通过前面几个小节，我们可以概括出神经网络构建的全过程：</p><p><strong>1. 初始化神经网络，随机的猜测 Q(s, a)。</strong></p><p>这就有点像训练线性回归模型时，随机的初始化所有参数，然后使用梯度下降一步一步完善。所以重要的其实是，算法能不能慢慢的改进参数，以获得更好的估计。</p><p><strong>2. 反复执行以下操作：</strong></p><p>2.1 在着陆期间，执行任何的操作，无论是好的还是坏的，你会获得多个这样的元组 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo separator="true">,</mo><mi>R</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(s, a, R(s), s&#39;)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p><p>2.2 重放缓冲区（Replay Buffer）：储存最新的 1 万个元组数据。</p><p>2.3 训练神经网络：将这 1 万个元组数据，通过贝尔曼方程构建成数据集。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mi>Q</mi><mo stretchy="false">(</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">maxQ(s&#39;, a&#39;)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em;"></span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 最开始是随机初始化的，没关系，通过训练慢慢就会变成 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><mi>R</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><mo>⋅</mo><mrow><mi>max</mi><mo>⁡</mo><mrow><mi>Q</mi><mo stretchy="false">(</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow></mrow><mo>≈</mo><mi>y</mi></mrow><annotation encoding="application/x-tex">Q_{new}(s, a)=R(s)+\gamma\cdot{\max{Q(s&#39;, a&#39;)}} \approx{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0019em;vertical-align:-0.25em;"></span><span class="mord"><span class="mop">max</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span></span></p><p>2.4 让 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo>=</mo><msub><mi>Q</mi><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q=Q_{new}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p><p>我们在反复执行训练神经网路的步骤中，Q(s, a) 是会继承上一次的训练结果的，所以每一次迭代，它都会变成更好的估计。</p><p>所以理论上来讲，只要你迭代的次数够多，训练的时间足够长，这个模拟着陆程序中的 DQN 就会变得足够好。</p><h2 id="_4-算法改进" tabindex="-1"><a class="header-anchor" href="#_4-算法改进"><span>4. 算法改进</span></a></h2><h3 id="_4-1-神经网络架构改进" tabindex="-1"><a class="header-anchor" href="#_4-1-神经网络架构改进"><span>4.1 神经网络架构改进</span></a></h3><figure><img src="/blog-pages/machinelearning/five/11-12.png" alt="11.12 强化学习中的神经网络" width="560" tabindex="0" loading="lazy"><figcaption>11.12 强化学习中的神经网络</figcaption></figure><p>这是原本的神经网络模型，我们需要在每个状态上，分别对四个动作进行推理。也就是一个状态就要运行四次神经网络，或者说每个动作都对应一个神经网络，这是非常低效的。</p><figure><img src="/blog-pages/machinelearning/five/11-14.png" alt="11.14 神经网络架构改进" width="560" tabindex="0" loading="lazy"><figcaption>11.14 神经网络架构改进</figcaption></figure><p>事实证明，在一个神经网络上同时计算并输出四个动作所对应的 Q 函数，效果会比原本的更好。因为通过贝尔曼方程，对比四个动作的回报，一次就可以知道在该状态下，做什么动作是最好的。</p><h3 id="_4-2-ε-贪婪策略-epsilon-greedy-policy" tabindex="-1"><a class="header-anchor" href="#_4-2-ε-贪婪策略-epsilon-greedy-policy"><span>4.2 ε-贪婪策略（Epsilon-greedy policy）</span></a></h3><p>当你处于某些状态时，可能并不想完全随机的采取行动，因为那样通常可能会是一个糟糕的结果。</p><p>我们原本的选项是：（1）选择一个动作 a，尽可能的最大化 Q(s, a)。即使它可能不尽人意，但是算法会尽力的使用我们当前对 Q(s, a)的猜测，并最大化它的收益。</p><p>而现在的选项是：<strong>（1）0.95 的概率，选择一个能最大化 Q(s, a)的动作 a。（2）0.05 的概率，随机选择一个动作 a。</strong></p><p>这么做的原因是，假设在随机初始化 Q(s ,a)的时候，出现了一些不好的情况，比如 Q(s, a)始终都很低，这可能导致该启动主推进器时，一直不启动的类似问题。</p><p>引入一个 0.05 的概率，神经网络可以学会克服自己的先入之见，也许自己之前坚持的才是错的呢？</p><p>这种随机选择动作的想法有时被称为探索步骤（Exploration Step）。还有一个很神奇的地方是，贪婪指的是 0.95 的概率，寻求 Q(s, a)最大化的部分，0.05 的随机探索才是不贪婪的。</p><p>一般来说，ε 的值是从大到小变化的。最初，你可能采取较多的随机行动，因为本身也不知道哪个好，哪个不好；</p><p>随着时间的推移，Q(s, a)迭代很多次后，已经有了很多好的推理，你可能会更倾向于用新的 Q(s, a)来估计和选择行动，所以随机行动就降低了。</p><h3 id="_4-3-超参数的敏感性" tabindex="-1"><a class="header-anchor" href="#_4-3-超参数的敏感性"><span>4.3 超参数的敏感性</span></a></h3><p>在监督学习中，超参数是不那么敏感的，比如，学习率选择的不好，可能也就是会让训练量或者说训练时间翻个两三倍。</p><p>但是强化学习中，超参数是很敏感的，假设你的 ε-贪婪策略中，epsilon 的值选的不够好，训练量可能会翻个 10 倍、100 倍。这非常恐怖。</p><p>吴恩达教授觉得，这可能是因为强化学习算法本身还不够完善导致的。目前，对于一个新项目而言，还需要我们自己试错。</p><h3 id="_4-4-小批量处理-mini-batch" tabindex="-1"><a class="header-anchor" href="#_4-4-小批量处理-mini-batch"><span>4.4 小批量处理（mini-batch）</span></a></h3><p>小批量处理可以加速强化学习和监督学习的训练速度，但是前提是你的训练集真的非常大，我们从监督学习的线性回归说起：</p><figure><img src="/blog-pages/machinelearning/five/11-15.png" alt="11.15 小批量处理1" width="560" tabindex="0" loading="lazy"><figcaption>11.15 小批量处理1</figcaption></figure><p>这是最初的房价预测的线性回归模型，但是假设有 1 亿个训练样本，本来在梯度下降时，更新参数 w 和 b 就要循环迭代很多次，再乘一个 1 亿的样本基数，训练时间会大到难以想想。</p><p><mark>小批量处理要做的事情就是，将其划分为不同的集合，一个集合中 1000 个样本、5000 个样本……<strong>然后在进行成本函数计算时，第一次用集合 1 的样本，第二次用集合 2 的样本，依次类推</strong>。</mark></p><figure><img src="/blog-pages/machinelearning/five/11-16.png" alt="11.16 小批量处理2" width="560" tabindex="0" loading="lazy"><figcaption>11.16 小批量处理2</figcaption></figure><p>一次性处理（Batch learning）的结果是，梯度会直接的向最小的地方前进，但是数据量太大了，计算时间会非常长。</p><p>小批量处理（Mini-Batch learning）的优势在于，计算成本要低得多，所以当数据集很大的时候，它是一个更快的算法。一般会和别的算法一起用，比如 adam。</p><p>缺点也很明显，可能会因为不同集合的样本走歪路，虽然它也会最终趋向于全局最优化，但是它不是很可靠，并且会有噪点。</p><figure><img src="/blog-pages/machinelearning/five/11-17.png" alt="11.17 小批量处理3" width="560" tabindex="0" loading="lazy"><figcaption>11.17 小批量处理3</figcaption></figure><p>回到强化学习中来，我们可以在训练神经网络模型的时候，使用小批量处理，将 1 万个数据，切分成 1000 个数据的不同集合。循环使用不同的集合来训练参数。</p><h3 id="_4-5-软更新" tabindex="-1"><a class="header-anchor" href="#_4-5-软更新"><span>4.5 软更新</span></a></h3><p>软更新可以帮助你的强化学习算法更好的收敛到一个好的解决方案。</p><p>在登月器的最后一步 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo>=</mo><msub><mi>Q</mi><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Q=Q_{new}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 中，有一个隐患，假如遇到了像小批量处理时，数据集不好的情况下，新的 Q 值可能会更糟糕。</p><figure><img src="/blog-pages/machinelearning/five/11-18.png" alt="11.18 软更新" width="560" tabindex="0" loading="lazy"><figcaption>11.18 软更新</figcaption></figure><p>我们可以给新的参数乘一个 0.01，旧的参数乘一个 0.99，这就是软更新，因为我们只会接受一点点的新值，所以出现错误的可能性大大降低，并且收敛性也会变得更佳。</p></div><!----><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/vuepress-theme-hope/vuepress-theme-hope/edit/main/src/zh/intelligence/MachineLearning/11_reinforcement_learning.md" aria-label="在 GitHub 上编辑此页" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->在 GitHub 上编辑此页<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">上次编辑于: </span><!----></div><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: zhangjk2021@gmail.com">zjk-laptop</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/blog-pages/zh/intelligence/MachineLearning/10_recommendation_system.html" aria-label="3-2 推荐系统"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><!---->3-2 推荐系统</div></a><!----></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">等我攒够了六便士，就去寻找月亮</div><div class="vp-copyright">Copyright © 2024 AOSAI </div></footer></div><!--]--><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/blog-pages/assets/app-CH05aeyc.js" defer></script>
  </body>
</html>
