import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as g,c as m,f as u,w as t,a as s,b as a,e as l,o as i}from"./app-C6YC_Rpq.js";const d="/blog-pages/machinelearning/five/11-01.png",y="/blog-pages/machinelearning/five/11-02.png",p="/blog-pages/machinelearning/five/11-03.png",r="/blog-pages/machinelearning/five/11-04.png",v="/blog-pages/machinelearning/five/11-05.png",_="/blog-pages/machinelearning/five/11-06.png",b="/blog-pages/machinelearning/five/11-07.png",x="/blog-pages/machinelearning/five/11-08.png",f="/blog-pages/machinelearning/five/11-09.png",k="/blog-pages/machinelearning/five/11-10.png",w="/blog-pages/machinelearning/five/11-11.png",c="/blog-pages/machinelearning/five/11-12.png",z="/blog-pages/machinelearning/five/11-13.png",R="/blog-pages/machinelearning/five/11-14.png",M="/blog-pages/machinelearning/five/11-15.png",Q="/blog-pages/machinelearning/five/11-16.png",B="/blog-pages/machinelearning/five/11-17.png",A="/blog-pages/machinelearning/five/11-18.png",D={},L=l('<p>强化学习（Reinforcement Learning）</p><h2 id="_1-强化学习概述" tabindex="-1"><a class="header-anchor" href="#_1-强化学习概述"><span>1. 强化学习概述</span></a></h2><p>在机器学习中，强化学习与其说是一类算法，不如说是一种思想，就和 <strong>贪心、动态规划、分治、回溯</strong> 这些经典的解决思路一样。虽然目前尚未在商业领域中得到广泛应用，但它也是机器学习的支柱之一。</p><p>我们还是从一个例子开始，图 11.1 是斯坦福大学自主研发的遥感直升机，重 32 磅。与其他遥感直升机一样，它配备了机载计算机、GPS、加速度计、陀螺仪和磁罗盘，因此它可以随时非常准确的知道自己的位置。</p><div class="layout"><figure><img src="'+d+'" alt="11.1 强化学习-遥感直升机1" width="360" tabindex="0" loading="lazy"><figcaption>11.1 强化学习-遥感直升机1</figcaption></figure><figure><img src="'+y+'" alt="11.2 强化学习-遥感直升机2" width="360" tabindex="0" loading="lazy"><figcaption>11.2 强化学习-遥感直升机2</figcaption></figure></div><p>遥感直升机的正常操作，就像 90 年代用手柄打卡带游戏一样，通过操作两个摇杆，以及不同的功能按钮，保持直升机在空中的平衡和飞行。</p><p>图 11.2 是吴恩达教授驾驶摇杆直升机的图像，仔细观察会发现，这个直升机它在倒着飞，有点像空中杂技。没错，它就是用强化学习做到的。如果你有兴趣看更多的视频，可以 <a href="http://heli.stanford.edu" target="_blank" rel="noopener noreferrer">点击此处</a>。</p><p>那么问题来了，如果给你一架摇杆直升机的密钥，让你来编写一个程序去自主驾驶它，你会怎么做？</p><h3 id="_1-1-什么是强化学习" tabindex="-1"><a class="header-anchor" href="#_1-1-什么是强化学习"><span>1.1 什么是强化学习</span></a></h3><p>假设我们给定一个任务：通过直升机的位置来决定如何移动驾驶杆。</p><p>我们将直升机的位置、方向、速度等称为状态 s。目标任务是找到一个函数，将直升机的状态映射到动作 a，即将两个操作杆推多远，以保证直升机在空中飞行时保持平衡不会坠毁。</p><p>这个任务也许能通过监督学习完成。比如我们有大量的状态观察结果，并且有一位专业的人类飞行员告诉我们应该采取的最佳行动是什么。然后你就可以使用监督学习训练神经网络，以直接学习 x（s）到标签 y（动作 a）的映射。</p><p>但事实证明，当直升机在空中移动时，“应该采取什么正确的行动”这个问题是很模糊的。比如向左倾斜时是一点还是很大？或者增加直升机压力是稍微还是很多？得到 x 和理想动作 y 的数据集是非常困难的。</p><p>这就是为什么对于很多控制机器人的任务，监督学习方法效果不佳，从而改为使用强化学习。<strong>强化学习的一个关键输入，叫做奖励（函数），它会告诉算法什么时候做的好，什么时候做的不好。</strong></p><p>对于奖励函数，在吴恩达教授看来就像是训练小狗。如何让小狗表现良好呢？你不能向小狗展示太多东西，相反，你只是让它做自己的事情，如果做的好，就鼓励夸夸，如果做了坏事，就凶它骂它。然后希望它自己学习如何做更多好的事情，做更少坏的事情。</p><p>强化学习算法也是这样，做的好的时候夸你，做的不好的时候骂你。比如直升机飞的好的时候，奖励它多飞 1 秒（+1）；飞的不好的时候，给一个负奖励，少飞 1 秒（-1）；如果坠毁，给一个非常大的负奖励，比如（-1000）。</p><h3 id="_1-2-形式-火星探测器" tabindex="-1"><a class="header-anchor" href="#_1-2-形式-火星探测器"><span>1.2 形式（火星探测器）</span></a></h3><figure><img src="'+p+'" alt="11.3 火星探测器1" width="560" tabindex="0" loading="lazy"><figcaption>11.3 火星探测器1</figcaption></figure><p>在这个简化的例子中，探测器有 6 个可能会移动的位置（状态）。假设探测器一开始在状态 4，它可以去不同的地方用它的传感器（探头、雷达、光谱仪等等）来分析火星上不同地方的岩石，或者拍摄有趣的照片供科学家们观看。</p><p>状态 1 和状态 6 都有非常有趣的地质结构，科学家们希望探测器对其采样，但状态 1 的有趣程度为 100 分，状态 6 的有趣程度为 40 分。其余的状态奖励为 0。</p><p>在每一步的决策中，探测器都可以选择向左走或者向右走。我们可以模拟几种情况来做说明：</p><ul><li>一直往左走，奖励为 [0, 0, 0, 100]</li><li>一直往右走，奖励为 [0, 0, 40]</li><li>先往右走一次，再往左走，奖励为 [0, 0, 0, 0, 0, 100]</li></ul><p>第三种情况很明显不太好，但是它也有可能会发生。</p><p>总而言之，每一个阶段，探测机器人都会处于某种状态（称为 s），它可以选择一个动作（称为 a），并且它还有一些从状态中获得的奖励（称为 R(s)），以及因为动作而产生的新的状态（称为 s&#39;）。</p><p>强化学习的核心要素就是这四件事：<strong>状态、动作、奖励、下一个状态</strong>，记录为：（s, a, R(s), s&#39;）。比如探测器从状态 4 往左走一次：（4, left, 0, 3）。</p><p>对于这个应用程序，假设它进入状态 1 或 6 时，这一天就结束了。这种情况在强化学习中被称为<strong>终端状态</strong>，意味着一旦到达终端状态之一后，获得奖励后就结束后续的动作。</p><h3 id="_1-3-回报-火星探测器" tabindex="-1"><a class="header-anchor" href="#_1-3-回报-火星探测器"><span>1.3 回报（火星探测器）</span></a></h3><p>回报这个概念，是强化学习中如何实施动作，做决策的关键。</p><p>做个有意思的类比：假设你站在分叉路口，往左走 5 分钟可以捡到一张 5 美元的钞票，往右走 30 分钟可以捡到一张 10 美元的钞票，你会往哪里走？</p><p>虽然 10 美元看起来比 5 美元好多了，但是如果要你花 30 分钟去拿那张 10 美元，也许你会觉得没有 5 美元来的更方便。</p><p>所以，在这个例子中，回报的概念抓住了你“更快获得奖励”可能比“需要更长时间才能获得奖励”更有吸引力。</p><p><strong>回报被定义为这些奖励的总和，但其中需要一个叫做“折扣因子（Gamma）”的东西加权。</strong> 还是火星探测器的图例：</p><figure><img src="'+p+'" alt="11.3 火星探测器1" width="560" tabindex="0" loading="lazy"><figcaption>11.3 火星探测器1</figcaption></figure><p>假设折扣因子为 0.9，我们从状态 4 一直向左移动到状态 1，它的回报是：</p>',34),C=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"R"),s("mi",null,"e"),s("mi",null,"t"),s("mi",null,"u"),s("mi",null,"r"),s("mi",null,"n"),s("mo",null,"="),s("mn",null,"0"),s("mo",null,"+"),s("mo",{stretchy:"false"},"("),s("mn",null,"0.9"),s("mo",{stretchy:"false"},")"),s("mo",null,"⋅"),s("mn",null,"0"),s("mo",null,"+"),s("mo",{stretchy:"false"},"("),s("mn",null,"0.9"),s("msup",null,[s("mo",{stretchy:"false"},")"),s("mn",null,"2")]),s("mo",null,"⋅"),s("mn",null,"0"),s("mo",null,"+"),s("mo",{stretchy:"false"},"("),s("mn",null,"0.9"),s("msup",null,[s("mo",{stretchy:"false"},")"),s("mn",null,"3")]),s("mo",null,"⋅"),s("mn",null,"100"),s("mo",null,"="),s("mn",null,"72.9")]),s("annotation",{encoding:"application/x-tex"}," Return=0+(0.9)\\cdot{0}+(0.9)^{2}\\cdot{0}+(0.9)^{3}\\cdot{100}=72.9 ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"u"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7278em","vertical-align":"-0.0833em"}}),s("span",{class:"mord"},"0"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"0.9"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"⋅"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7278em","vertical-align":"-0.0833em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"0")]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1141em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"0.9"),s("span",{class:"mclose"},[s("span",{class:"mclose"},")"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"⋅"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7278em","vertical-align":"-0.0833em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"0")]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1141em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"0.9"),s("span",{class:"mclose"},[s("span",{class:"mclose"},")"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"3")])])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"⋅"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6444em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"100")]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6444em"}}),s("span",{class:"mord"},"72.9")])])])])],-1),E=s("p",null,"我们可以看到，折扣因子 Gamma 是指数型增长，越到后面越小。吴恩达教授的解释很有趣，他说：Gamma 的作用是让强化学习有点不耐烦。这样它就会往奖励越大的、越靠近的状态上靠。",-1),q=s("p",null,"用符号归纳一下回报的函数，它可以写为：",-1),T=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"R"),s("mi",null,"e"),s("mi",null,"t"),s("mi",null,"u"),s("mi",null,"r"),s("mi",null,"n"),s("mo",null,"="),s("msub",null,[s("mi",null,"R"),s("mn",null,"1")]),s("mo",null,"+"),s("mi",null,"γ"),s("msub",null,[s("mi",null,"R"),s("mn",null,"2")]),s("mo",null,"+"),s("msup",null,[s("mi",null,"γ"),s("mn",null,"2")]),s("msub",null,[s("mi",null,"R"),s("mn",null,"3")]),s("mo",null,"+"),s("mo",null,"⋯")]),s("annotation",{encoding:"application/x-tex"}," Return=R_{1}+\\gamma{R_{2}}+\\gamma^{2}{R_{3}}+\\cdots ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"u"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8778em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0585em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"3")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.313em"}}),s("span",{class:"minner"},"⋯")])])])])],-1),F=l('<p>在许多强化学习算法中，折扣因子的选择是非常接近 1 的数字，比如 0.9，0.99，甚至 0.999。但是为了能从另一个角度，更好的理解回报的原理，这里 Gamma 选择了 0.5。</p><figure><img src="'+r+'" alt="11.4 火星探测器2" width="560" tabindex="0" loading="lazy"><figcaption>11.4 火星探测器2</figcaption></figure><p>图中的三行数据，每一行里红色的数字表示回报，黄色的箭头表示在该状态下往哪边走，黑色的数字代表奖励。三种不同的移动模式所带来的回报，差别是很明显的。</p><h3 id="_1-4-决策-火星探测器" tabindex="-1"><a class="header-anchor" href="#_1-4-决策-火星探测器"><span>1.4 决策（火星探测器）</span></a></h3><p>如同前几个小节所讲，强化学习中可以采取多种不同的方式，去决定下一个动作该做什么，比如在火星探测器中：</p><ol><li>总是追求更接近的奖励。靠近左边就往左边走，靠近右边就往右边走。</li><li>总是追求更大的奖励。状态 1 奖励最大，所以总是往左走。</li><li>总是追求更小的奖励。总是往右走，虽然看起来不是一个好主意，但也是一种选择。</li><li>往更大的奖励走，除非距离较小的奖励仅一步之遥。状态 234 往左走，状态 5 往右走。</li></ol><figure><img src="'+v+'" alt="11.5 火星探测器3" width="560" tabindex="0" loading="lazy"><figcaption>11.5 火星探测器3</figcaption></figure><p>在强化学习中，我们的目标是提出一个称为 策略 Pi 的函数，将任何状态 s 作为输入并将其映射到它希望我们采取的某个动作 a。比如策略 Pi 选择了第 4 种方式，那么探测机器人就会按照第 4 种方式去移动。</p><p>强化学习的目标是找到一个策略 Pi，告诉你在不同的状态下，采取什么行动可以获得最大化的回报。</p><h3 id="_1-5-回顾总结" tabindex="-1"><a class="header-anchor" href="#_1-5-回顾总结"><span>1.5 回顾总结</span></a></h3><p>我们用 6 种状态的火星探测器示例初步讲解了强化学习的形式，让我们快速回顾一下关键概念，并了解如何将这组概念应用于其他的程序。</p><figure><img src="'+_+'" alt="11.6 回顾小结" width="560" tabindex="0" loading="lazy"><figcaption>11.6 回顾小结</figcaption></figure><p>火星探测器和遥感直升机已经在前面说过了，第三个是国际象棋。假设你想使用强化学习来学习下棋：</p>',13),S=s("ul",null,[s("li",null,[s("strong",null,"状态"),a("：棋盘上所有棋子的位置（简化版）。")]),s("li",null,[s("strong",null,"动作"),a("：游戏中合法的移动。")]),s("li",null,[s("strong",null,"奖励"),a("：常见方式为，赢了奖励+1，输了负奖励-1，零奖励可能与游戏有关。")]),s("li",null,[s("strong",null,"折扣因子"),a("：国际象棋通常 Gamma 为接近 1 的数字，比如 0.99。")]),s("li",null,[s("strong",null,"回报"),a("："),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"R"),s("mn",null,"1")]),s("mo",null,"+"),s("mi",null,"γ"),s("msub",null,[s("mi",null,"R"),s("mn",null,"2")]),s("mo",null,"+"),s("msup",null,[s("mi",null,"γ"),s("mn",null,"2")]),s("msub",null,[s("mi",null,"R"),s("mn",null,"3")]),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},".")]),s("annotation",{encoding:"application/x-tex"},"R_{1}+\\gamma{R_{2}}+\\gamma^{2}{R_{3}} ...")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8778em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0085em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"3")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mord"},"...")])])])]),s("li",null,[s("strong",null,"决策"),a("：目标棋子被赋予了一个棋盘位置，使用策略 Pi 选择一个好的动作。")])],-1),N=l('<p>这种强化学习应用程序的形式实际上有一个名字，叫做：<strong>马尔可夫决策过程（Markov Decision Process，MDP）</strong>。它是指：未来仅取决于当前的状态，而不是取决于到达当前状态之前可能发生的任何事情。</p><h2 id="_2-状态-动作价值函数" tabindex="-1"><a class="header-anchor" href="#_2-状态-动作价值函数"><span>2. 状态-动作价值函数</span></a></h2><p>状态-动作价值函数（State-action value function）的目的是为了寻找当前状态下，回报最大的动作。也就是让回报最大化，它的形式可以写为循环：</p><p>Q(s, a) = Return if you</p><ul><li>start in state s.</li><li>take action a (just once).</li><li>then behave optimally after that.</li></ul><figure><img src="'+r+'" alt="11.4 火星探测器2" width="560" tabindex="0" loading="lazy"><figcaption>11.4 火星探测器2</figcaption></figure><p>这是 1.3 小节中讲回报的图，第一行是火星探测车全向左走，第二行是全向右走。我们将这两行的回报结合起来，对比大小来看，第三行其实就是最大回报的动作决策。</p><p>另外，因为这个函数总是被写作 Q 函数，或者 Q*函数（optimal Q function），所以如果你在很多文献里看到了它们，不要惊讶，它们就表示状态-动作价值函数。</p><h3 id="_2-1-代码示例" tabindex="-1"><a class="header-anchor" href="#_2-1-代码示例"><span>2.1 代码示例</span></a></h3><p>这是吴恩达教授简化的代码（<a href="/machinelearning/five/utils.py" target="_blank" rel="noopener noreferrer">utils.py 文件可以从此处打开</a>），他希望我们通过自己修改一些参数，比如更改两边的奖励数值、更改折扣因子的大小等等，看看自动策略会如何根据这些不同的值而变化。</p>',10),P=s("div",{class:"language-py line-numbers-mode","data-highlighter":"shiki","data-ext":"py","data-title":"py",style:{"--shiki-light":"#24292e","--shiki-dark":"#abb2bf","--shiki-light-bg":"#fff","--shiki-dark-bg":"#282c34"}},[s("pre",{class:"shiki shiki-themes github-light one-dark-pro vp-code"},[s("code",null,[s("span",{class:"line"},[s("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#C678DD"}},"import"),s("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#ABB2BF"}}," numpy "),s("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#C678DD"}},"as"),s("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#ABB2BF"}}," np")]),a(`
`),s("span",{class:"line"},[s("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#C678DD"}},"from"),s("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#ABB2BF"}}," utils "),s("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#C678DD"}},"import"),s("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#56B6C2"}}," *")]),a(`
`),s("span",{class:"line"}),a(`
`),s("span",{class:"line"},[s("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#ABB2BF"}},"num_states "),s("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#56B6C2"}},"="),s("span",{style:{"--shiki-light":"#005CC5","--shiki-dark":"#D19A66"}}," 6")]),a(`
`),s("span",{class:"line"},[s("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#ABB2BF"}},"num_actions "),s("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#56B6C2"}},"="),s("span",{style:{"--shiki-light":"#005CC5","--shiki-dark":"#D19A66"}}," 2")]),a(`
`),s("span",{class:"line"}),a(`
`),s("span",{class:"line"},[s("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#ABB2BF"}},"terminal_left_reward "),s("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#56B6C2"}},"="),s("span",{style:{"--shiki-light":"#005CC5","--shiki-dark":"#D19A66"}}," 100")]),a(`
`),s("span",{class:"line"},[s("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#ABB2BF"}},"terminal_right_reward "),s("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#56B6C2"}},"="),s("span",{style:{"--shiki-light":"#005CC5","--shiki-dark":"#D19A66"}}," 40")]),a(`
`),s("span",{class:"line"},[s("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#ABB2BF"}},"each_step_reward "),s("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#56B6C2"}},"="),s("span",{style:{"--shiki-light":"#005CC5","--shiki-dark":"#D19A66"}}," 0")]),a(`
`),s("span",{class:"line"}),a(`
`),s("span",{class:"line"},[s("span",{style:{"--shiki-light":"#6A737D","--shiki-dark":"#7F848E","--shiki-light-font-style":"inherit","--shiki-dark-font-style":"italic"}},"# Discount factor")]),a(`
`),s("span",{class:"line"},[s("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#ABB2BF"}},"gamma "),s("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#56B6C2"}},"="),s("span",{style:{"--shiki-light":"#005CC5","--shiki-dark":"#D19A66"}}," 0.5")]),a(`
`),s("span",{class:"line"},[s("span",{style:{"--shiki-light":"#6A737D","--shiki-dark":"#7F848E","--shiki-light-font-style":"inherit","--shiki-dark-font-style":"italic"}},"#probability of going in the wrong direction")]),a(`
`),s("span",{class:"line"},[s("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#ABB2BF"}},"misstep_prob "),s("span",{style:{"--shiki-light":"#D73A49","--shiki-dark":"#56B6C2"}},"="),s("span",{style:{"--shiki-light":"#005CC5","--shiki-dark":"#D19A66"}}," 0")]),a(`
`),s("span",{class:"line"}),a(`
`),s("span",{class:"line"},[s("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#61AFEF"}},"generate_visualization"),s("span",{style:{"--shiki-light":"#24292E","--shiki-dark":"#ABB2BF"}},"(terminal_left_reward, terminal_right_reward, each_step_reward, gamma, misstep_prob)")])])]),s("div",{class:"line-numbers","aria-hidden":"true",style:{"counter-reset":"line-number 0"}},[s("div",{class:"line-number"}),s("div",{class:"line-number"}),s("div",{class:"line-number"}),s("div",{class:"line-number"}),s("div",{class:"line-number"}),s("div",{class:"line-number"}),s("div",{class:"line-number"}),s("div",{class:"line-number"}),s("div",{class:"line-number"}),s("div",{class:"line-number"}),s("div",{class:"line-number"}),s("div",{class:"line-number"}),s("div",{class:"line-number"}),s("div",{class:"line-number"}),s("div",{class:"line-number"}),s("div",{class:"line-number"})])],-1),G=s("figure",null,[s("img",{src:b,alt:"11.7 状态-动作价值函数",width:"560",tabindex:"0",loading:"lazy"}),s("figcaption",null,"11.7 状态-动作价值函数")],-1),Z=s("p",null,"有的同学可能看了运行结果会问，为什么状态 2 和状态 3 向右走的回报，不是 2.5 和 5，反而是 12.5 和 6.25 呢。因为这两个状态向右走的策略是：先往右走一次，然后一直往左走。",-1),j=s("p",null,"Q 函数的目的是找寻回报最大化的动作，在状态 2 中，12.5 明显比 2.5 大，所以迂回的走法比一直向右走看起来更好，状态 3 同理。",-1),O=s("p",null,"此外，misstep_prob 这个参数详情，请看 2.3 小节，随机环境。",-1),V=s("h3",{id:"_2-2-贝尔曼方程-bellman-equation",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#_2-2-贝尔曼方程-bellman-equation"},[s("span",null,"2.2 贝尔曼方程（Bellman Equation）")])],-1),I=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{separator:"true"},","),s("mi",null,"a"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"R"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{stretchy:"false"},")"),s("mo",null,"+"),s("mi",null,"γ"),s("mo",null,"⋅"),s("mrow",null,[s("mi",null,"max"),s("mo",null,"⁡"),s("mrow",null,[s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("msup",null,[s("mi",null,"s"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",{separator:"true"},","),s("msup",null,[s("mi",null,"a"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",{stretchy:"false"},")")])])]),s("annotation",{encoding:"application/x-tex"}," Q(s, a)=R(s)+\\gamma\\cdot{\\max{Q(s', a')}} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6389em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"⋅"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0519em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mop"},"max"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"s"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8019em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8019em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])]),s("span",{class:"mclose"},")")])])])])])])],-1),H=s("p",null,"贝尔曼方程简单的来说，就是告诉我们，当前状态下该动作的回报，是由（1）当前状态的奖励，也称作即时奖励；（2）折扣因子 × 下一个状态的回报最大的动作；两个部分组成。它其实可以看作是对回报的拆分：",-1),Y=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mtable",{rowspacing:"0.25em",columnalign:"right left",columnspacing:"0em"},[s("mtr",null,[s("mtd",{class:"mtr-glue"}),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mi",null,"R"),s("mi",null,"e"),s("mi",null,"t"),s("mi",null,"u"),s("mi",null,"r"),s("mi",null,"n")])])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("mo",null,"="),s("msub",null,[s("mi",null,"R"),s("mn",null,"1")]),s("mo",null,"+"),s("mi",null,"γ"),s("msub",null,[s("mi",null,"R"),s("mn",null,"2")]),s("mo",null,"+"),s("msup",null,[s("mi",null,"γ"),s("mn",null,"2")]),s("msub",null,[s("mi",null,"R"),s("mn",null,"3")]),s("mo",null,"+"),s("mo",null,"⋯")])])]),s("mtd",{class:"mtr-glue"}),s("mtd",{class:"mml-eqn-num"})]),s("mtr",null,[s("mtd",{class:"mtr-glue"}),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow")])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("mo",null,"="),s("msub",null,[s("mi",null,"R"),s("mn",null,"1")]),s("mo",null,"+"),s("mi",null,"γ"),s("mrow",null,[s("mo",{stretchy:"false"},"["),s("msub",null,[s("mi",null,"R"),s("mn",null,"2")]),s("mo",null,"+"),s("mi",null,"γ"),s("msub",null,[s("mi",null,"R"),s("mn",null,"3")]),s("mo",null,"+"),s("mo",null,"⋯"),s("mtext",null," "),s("mo",{stretchy:"false"},"]")])])])]),s("mtd",{class:"mtr-glue"}),s("mtd",{class:"mml-eqn-num"})]),s("mtr",null,[s("mtd",{class:"mtr-glue"}),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow")])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("mo",null,"="),s("mi",null,"R"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{stretchy:"false"},")"),s("mo",null,"+"),s("mi",null,"γ"),s("mo",null,"⋅"),s("mrow",null,[s("mi",null,"max"),s("mo",null,"⁡"),s("mrow",null,[s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("msup",null,[s("mi",null,"s"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",{separator:"true"},","),s("msup",null,[s("mi",null,"a"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",{stretchy:"false"},")")])])])])]),s("mtd",{class:"mtr-glue"}),s("mtd",{class:"mml-eqn-num"})])]),s("annotation",{encoding:"application/x-tex"}," \\begin{align} Return &= R_{1}+\\gamma{R_{2}}+\\gamma^{2}{R_{3}}+\\cdots \\\\ &= R_{1}+\\gamma{[R_{2}+\\gamma{R_{3}}+\\cdots]} \\\\ &= R(s)+\\gamma\\cdot{\\max{Q(s', a')}} \\end{align} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"4.5241em","vertical-align":"-2.0121em"}}),s("span",{class:"mtable"},[s("span",{class:"col-align-r"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2.5121em"}},[s("span",{style:{top:"-4.6479em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"u"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mord mathnormal"},"n")])]),s("span",{style:{top:"-3.1479em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"})]),s("span",{style:{top:"-1.6479em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"})])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2.0121em"}},[s("span")])])])]),s("span",{class:"col-align-l"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2.5121em"}},[s("span",{style:{top:"-4.6479em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"3")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"minner"},"⋯")])]),s("span",{style:{top:"-3.1479em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mord"},[s("span",{class:"mopen"},"["),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"3")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"minner"},"⋯"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mclose"},"]")])])]),s("span",{style:{top:"-1.6479em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"⋅"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mop"},"max"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"s"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8019em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8019em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])]),s("span",{class:"mclose"},")")])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2.0121em"}},[s("span")])])])])])]),s("span",{class:"tag"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2.5121em"}},[s("span",{style:{top:"-4.5121em"}},[s("span",{class:"pstrut",style:{height:"2.8641em"}}),s("span",{class:"eqn-num"})]),s("span",{style:{top:"-3.0121em"}},[s("span",{class:"pstrut",style:{height:"2.8641em"}}),s("span",{class:"eqn-num"})]),s("span",{style:{top:"-1.5121em"}},[s("span",{class:"pstrut",style:{height:"2.8641em"}}),s("span",{class:"eqn-num"})])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"2.0121em"}},[s("span")])])])])])])])],-1),J=l('<figure><img src="'+x+'" alt="11.8 贝尔曼方程" width="560" tabindex="0" loading="lazy"><figcaption>11.8 贝尔曼方程</figcaption></figure><p>图 11.8 中举了两个例子，从状态 2 往右走，计算出来 12.5 就是它的最大回报；从状态 4 往左走，12.5 是它的最大回报。</p><h3 id="_2-3-随机环境" tabindex="-1"><a class="header-anchor" href="#_2-3-随机环境"><span>2.3 随机环境</span></a></h3><p>在实践中，由于刮风、偏离航线、车轮打滑等等原因，许多机器人没有办法完全按照你的要求去做，所以结果并不会总是可靠。</p><p>比如，在火星探测器向左行驶的途中，可能会遇见岩石滑坡，或者地面真的很滑，导致它滑向了错误的方向。</p><p>我们可以模拟它出现错误的概率，比如 90%的概率会正常运行，10%的概率会遭遇意外情况。比如：</p><ul><li>从状态 3 向左走，没有出错：[0, 0, 100]</li><li>从状态 3 向左走，在状态 2 时打滑了一次，回到了状态 3：[0, 0, 0, 0, 100]</li></ul><p>我们会发现，加入概率之后啊，回报就不是一个准确的公式，而是无数个公式的集合，我们需要取它的平均值，或者说是期望，来重新测定每个状态，往左或往右走的回报。</p>',8),K=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mtable",{rowspacing:"0.25em",columnalign:"right left",columnspacing:"0em"},[s("mtr",null,[s("mtd",{class:"mtr-glue"}),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mi",null,"E"),s("mi",null,"x"),s("mi",null,"p"),s("mi",null,"e"),s("mi",null,"c"),s("mi",null,"t"),s("mi",null,"e"),s("mi",null,"d"),s("mi",{mathvariant:"normal"},"_"),s("mi",null,"R"),s("mi",null,"e"),s("mi",null,"t"),s("mi",null,"u"),s("mi",null,"r"),s("mi",null,"n")])])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("mo",null,"="),s("mi",null,"A"),s("mi",null,"v"),s("mi",null,"e"),s("mi",null,"r"),s("mi",null,"a"),s("mi",null,"g"),s("mi",null,"e"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"R"),s("mn",null,"1")]),s("mo",null,"+"),s("mi",null,"γ"),s("msub",null,[s("mi",null,"R"),s("mn",null,"2")]),s("mo",null,"+"),s("msup",null,[s("mi",null,"γ"),s("mn",null,"2")]),s("msub",null,[s("mi",null,"R"),s("mn",null,"3")]),s("mo",null,"+"),s("mo",null,"⋯"),s("mtext",null," "),s("mo",{stretchy:"false"},")")])])]),s("mtd",{class:"mtr-glue"}),s("mtd",{class:"mml-eqn-num"})]),s("mtr",null,[s("mtd",{class:"mtr-glue"}),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow")])]),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mrow"),s("mo",null,"="),s("mi",null,"E"),s("mo",{stretchy:"false"},"["),s("msub",null,[s("mi",null,"R"),s("mn",null,"1")]),s("mo",null,"+"),s("mi",null,"γ"),s("msub",null,[s("mi",null,"R"),s("mn",null,"2")]),s("mo",null,"+"),s("msup",null,[s("mi",null,"γ"),s("mn",null,"2")]),s("msub",null,[s("mi",null,"R"),s("mn",null,"3")]),s("mo",null,"+"),s("mo",null,"⋯"),s("mtext",null," "),s("mo",{stretchy:"false"},"]")])])]),s("mtd",{class:"mtr-glue"}),s("mtd",{class:"mml-eqn-num"})])]),s("annotation",{encoding:"application/x-tex"}," \\begin{align} Expected\\_Return &= Average(R_{1}+\\gamma{R_{2}}+\\gamma^{2}{R_{3}}+\\cdots) \\\\ &= E[R_{1}+\\gamma{R_{2}}+\\gamma^{2}{R_{3}}+\\cdots] \\end{align} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"3.0482em","vertical-align":"-1.2741em"}}),s("span",{class:"mtable"},[s("span",{class:"col-align-r"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.7741em"}},[s("span",{style:{top:"-3.91em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"E"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mord mathnormal"},"p"),s("span",{class:"mord mathnormal"},"ec"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"d"),s("span",{class:"mord",style:{"margin-right":"0.02778em"}},"_"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"u"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mord mathnormal"},"n")])]),s("span",{style:{top:"-2.3859em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"})])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.2741em"}},[s("span")])])])]),s("span",{class:"col-align-l"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.7741em"}},[s("span",{style:{top:"-3.91em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal"},"A"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"v"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"er"),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"g"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"3")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"minner"},"⋯"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mclose"},")")])]),s("span",{style:{top:"-2.3859em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"E"),s("span",{class:"mopen"},"["),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"3")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"minner"},"⋯"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mclose"},"]")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.2741em"}},[s("span")])])])])])]),s("span",{class:"tag"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.7741em"}},[s("span",{style:{top:"-3.7741em"}},[s("span",{class:"pstrut",style:{height:"2.8641em"}}),s("span",{class:"eqn-num"})]),s("span",{style:{top:"-2.25em"}},[s("span",{class:"pstrut",style:{height:"2.8641em"}}),s("span",{class:"eqn-num"})])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.2741em"}},[s("span")])])])])])])])],-1),U=s("p",null,"可以修改 2.1 小节中代码参数 misstep_prob，做对比观察。同理，对于贝尔曼方程，我们也需要改写为期望的形式。",-1),W=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{separator:"true"},","),s("mi",null,"a"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"R"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{stretchy:"false"},")"),s("mo",null,"+"),s("mi",null,"γ"),s("mo",null,"⋅"),s("mrow",null,[s("mi",null,"E"),s("mo",{stretchy:"false"},"["),s("mi",null,"max"),s("mo",null,"⁡"),s("mrow",null,[s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("msup",null,[s("mi",null,"s"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",{separator:"true"},","),s("msup",null,[s("mi",null,"a"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",{stretchy:"false"},")")]),s("mo",{stretchy:"false"},"]")])]),s("annotation",{encoding:"application/x-tex"}," Q(s, a) = R(s)+\\gamma\\cdot{E[\\max{Q(s', a')}]} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6389em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"⋅"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0519em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"E"),s("span",{class:"mopen"},"["),s("span",{class:"mop"},"max"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"s"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8019em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8019em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])]),s("span",{class:"mclose"},")")]),s("span",{class:"mclose"},"]")])])])])])],-1),X=s("h2",{id:"_3-连续的状态空间",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#_3-连续的状态空间"},[s("span",null,"3. 连续的状态空间")])],-1),$=s("p",null,"我们使用的简化版火星探测器，是一组离散的状态，它意味着探测器只可能处于 6 个位置中的一个。",-1),ss=s("p",null,"但事实上，它可以处于大量连续位置中的任何一个。比如，一条横向的 6 公里长的直线，我们以米作为单位，向左或向右走时，[0, 6000]m 以内的任何数字都是有效的。",-1),as=s("figure",null,[s("img",{src:f,alt:"11.9 连续的状态空间",width:"560",tabindex:"0",loading:"lazy"}),s("figcaption",null,"11.9 连续的状态空间")],-1),ls=s("p",null,[a("我们再举一个例子，比如正在行驶的卡车（玩具车），它需要考虑的就不只是一个状态了，比如，前后方向的位置 x，左右方向的位置 y，卡车行驶的方向 θ，以及前后方向的速度 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"x"),s("mo",null,"˙")])]),s("annotation",{encoding:"application/x-tex"},"\\dot{x}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6679em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6679em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"x")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1111em"}},[s("span",{class:"mord"},"˙")])])])])])])])])]),a("，左右方向的速度 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"y"),s("mo",null,"˙")])]),s("annotation",{encoding:"application/x-tex"},"\\dot{y}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8623em","vertical-align":"-0.1944em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6679em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.0833em"}},[s("span",{class:"mord"},"˙")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])])])])]),a("，行驶方向/角度变化的速度 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"d"),s("mi",null,"o"),s("mi",null,"t"),s("mi",null,"θ")]),s("annotation",{encoding:"application/x-tex"},"dot{\\theta}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal"},"d"),s("span",{class:"mord mathnormal"},"o"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ")])])])]),a("。")],-1),ts=s("p",null,[a("所以卡车的状态将包含由这 6 个符号组成的向量："),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"s"),s("mo",null,"="),s("mo",{stretchy:"false"},"["),s("mi",null,"x"),s("mo",{separator:"true"},","),s("mi",null,"y"),s("mo",{separator:"true"},","),s("mi",null,"θ"),s("mo",{separator:"true"},","),s("mover",{accent:"true"},[s("mi",null,"x"),s("mo",null,"˙")]),s("mo",{separator:"true"},","),s("mover",{accent:"true"},[s("mi",null,"y"),s("mo",null,"˙")]),s("mo",{separator:"true"},","),s("mover",{accent:"true"},[s("mi",null,"θ"),s("mo",null,"˙")]),s("msup",null,[s("mo",{stretchy:"false"},"]"),s("mi",null,"T")])]),s("annotation",{encoding:"application/x-tex"},"s=[x, y, \\theta, \\dot{x}, \\dot{y}, \\dot{\\theta}]^{T}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1813em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"["),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6679em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"x")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1111em"}},[s("span",{class:"mord"},"˙")])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6679em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.0833em"}},[s("span",{class:"mord"},"˙")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.9313em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ")]),s("span",{style:{top:"-3.2634em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.0556em"}},[s("span",{class:"mord"},"˙")])])])])])]),s("span",{class:"mclose"},[s("span",{class:"mclose"},"]"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8413em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"T")])])])])])])])])])])]),a("，并且这些符号中的任何一个，都可以采用有效范围内的任何值。比如方向/角度的范围为 0 到 360°。")],-1),ns=l('<h3 id="_3-1-登月器" tabindex="-1"><a class="header-anchor" href="#_3-1-登月器"><span>3.1 登月器</span></a></h3><figure><img src="'+k+'" alt="11.10 登月器" width="560" tabindex="0" loading="lazy"><figcaption>11.10 登月器</figcaption></figure><p>这是一个很有意思的模拟月球着陆的程序，每个时间点你可以有四种操作：</p><ol><li>什么都不做，让惯性和重力将着陆器拉向月球表面。</li><li>启动左侧推进器，将着陆器推向右边移动。</li><li>启动右侧推进器，将着陆器推向左边移动。</li><li>启动底部的主推进器，减缓下降的速度。</li></ol><p>你的任务就是随着时间的推移，不断地选择行动，让着陆器安全的降落在两个黄旗中间的位置。那么它的状态向量都包含些什么呢？</p>',5),es=s("ul",null,[s("li",null,"x 和 y 表示在水平方向和垂直方向的位置"),s("li",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"x"),s("mo",null,"˙")]),s("mtext",null,"和"),s("mover",{accent:"true"},[s("mi",null,"y"),s("mo",null,"˙")])]),s("annotation",{encoding:"application/x-tex"},"\\dot{x}和\\dot{y}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8778em","vertical-align":"-0.1944em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6679em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"x")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1111em"}},[s("span",{class:"mord"},"˙")])])])])])]),s("span",{class:"mord cjk_fallback"},"和"),s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6679em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.0833em"}},[s("span",{class:"mord"},"˙")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])])])])]),a(" 表示在横轴和纵轴上的移动速度")]),s("li",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"θ")]),s("annotation",{encoding:"application/x-tex"},"\\theta")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ")])])]),a(" 表示着陆器的角度，也就是机身的倾斜程度")]),s("li",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"θ"),s("mo",null,"˙")])]),s("annotation",{encoding:"application/x-tex"},"\\dot{\\theta}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.9313em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.9313em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ")]),s("span",{style:{top:"-3.2634em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.0556em"}},[s("span",{class:"mord"},"˙")])])])])])])])])]),a(" 表示倾斜的速度，或者说角速度")]),s("li",null,"l 和 r 是两个布尔类型的变量，对应：左腿是否着地、右腿是否着地")],-1),ms=l('<p>它的奖励函数也很有趣，之前的火星探测器，只有两个状态存在奖励，而这次的着陆器有 7 种奖励，并且包括负奖励：</p><figure><img src="'+w+'" alt="11.11 登月器的奖励函数" width="560" tabindex="0" loading="lazy"><figcaption>11.11 登月器的奖励函数</figcaption></figure><ol><li>假设两根黄旗中间有一个垫子，着陆器正在设法降落在上面，我们根据降落途中的飞行情况，给 100~140 的奖励；</li><li>并且有一个额外的奖励，离垫子中心越近，奖励越高，离垫子中心越远，奖励越低；</li><li>如果坠毁，奖励-100；</li><li>软着陆成功，奖励+100；</li><li>每条腿落地，都会奖励+10；</li><li>假设我们鼓励它节省燃料，所以每次启动主引擎（主推进器）时，奖励-0.3；</li><li>每次触发左侧或右侧推进器时，奖励-0.03。</li></ol><p>这是一个中等复杂程度的奖励函数，设计者对真正你想要的行为进行了一些思考，并将其编入奖励函数中，激励更多你想要的行为。</p><p>当你自己构建一个强化学习应用程序时，通常你会花些心思来准确的指定你想要什么，你不想要什么，以及将其编入奖励函数。</p>',5),is=s("p",null,[a("总结一下，着陆器程序的任务是：在给定状态向量 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"s"),s("mo",null,"="),s("mo",{stretchy:"false"},"["),s("mi",null,"x"),s("mo",{separator:"true"},","),s("mi",null,"y"),s("mo",{separator:"true"},","),s("mover",{accent:"true"},[s("mi",null,"x"),s("mo",null,"˙")]),s("mo",{separator:"true"},","),s("mover",{accent:"true"},[s("mi",null,"y"),s("mo",null,"˙")]),s("mo",{separator:"true"},","),s("mi",null,"θ"),s("mo",{separator:"true"},","),s("mover",{accent:"true"},[s("mi",null,"θ"),s("mo",null,"˙")]),s("mo",{separator:"true"},","),s("mi",null,"l"),s("mo",{separator:"true"},","),s("mi",null,"r"),s("msup",null,[s("mo",{stretchy:"false"},"]"),s("mi",null,"T")])]),s("annotation",{encoding:"application/x-tex"},"s=[x, y, \\dot{x}, \\dot{y}, \\theta, \\dot{\\theta}, l, r]^{T}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1813em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"["),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6679em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"x")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1111em"}},[s("span",{class:"mord"},"˙")])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6679em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.0833em"}},[s("span",{class:"mord"},"˙")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.9313em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ")]),s("span",{style:{top:"-3.2634em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.0556em"}},[s("span",{class:"mord"},"˙")])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mclose"},[s("span",{class:"mclose"},"]"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8413em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"T")])])])])])])])])])])]),a(" 的情况下，让决策 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"π")]),s("annotation",{encoding:"application/x-tex"},"\\pi")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"π")])])]),a(" 选择一个最佳的动作 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"a"),s("mo",null,"="),s("mi",null,"π"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"a=\\pi(s)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"π"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},")")])])]),a("，使得回报最大化，折扣因子选定为 Gamma=0.985。")],-1),ps=s("h3",{id:"_3-2-强化学习中的神经网络",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#_3-2-强化学习中的神经网络"},[s("span",null,"3.2 强化学习中的神经网络")])],-1),rs=s("p",null,"用强化学习来解决登月器或者其它问题的一个关键思想是，我们要训练一个神经网络来计算或近似 state，action 的状态动作价值函数 Q。这反过来又会让我们选择一个好的行动。",-1),cs=s("figure",null,[s("img",{src:c,alt:"11.12 强化学习中的神经网络",width:"560",tabindex:"0",loading:"lazy"}),s("figcaption",null,"11.12 强化学习中的神经网络")],-1),hs=s("p",null,[a("神经网络的输入包含了所有的状态和动作，状态向量已经写过了："),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"s"),s("mo",null,"="),s("mo",{stretchy:"false"},"["),s("mi",null,"x"),s("mo",{separator:"true"},","),s("mi",null,"y"),s("mo",{separator:"true"},","),s("mover",{accent:"true"},[s("mi",null,"x"),s("mo",null,"˙")]),s("mo",{separator:"true"},","),s("mover",{accent:"true"},[s("mi",null,"y"),s("mo",null,"˙")]),s("mo",{separator:"true"},","),s("mi",null,"θ"),s("mo",{separator:"true"},","),s("mover",{accent:"true"},[s("mi",null,"θ"),s("mo",null,"˙")]),s("mo",{separator:"true"},","),s("mi",null,"l"),s("mo",{separator:"true"},","),s("mi",null,"r"),s("msup",null,[s("mo",{stretchy:"false"},"]"),s("mi",null,"T")])]),s("annotation",{encoding:"application/x-tex"},"s=[x, y, \\dot{x}, \\dot{y}, \\theta, \\dot{\\theta}, l, r]^{T}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1813em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"["),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6679em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"x")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1111em"}},[s("span",{class:"mord"},"˙")])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6679em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.0833em"}},[s("span",{class:"mord"},"˙")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.9313em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ")]),s("span",{style:{top:"-3.2634em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.0556em"}},[s("span",{class:"mord"},"˙")])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mclose"},[s("span",{class:"mclose"},"]"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8413em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.13889em"}},"T")])])])])])])])])])])]),a("；4 个动作我们可以通过 one-hot 进行编码：")],-1),os=s("ul",null,[s("li",null,"nothing，什么都不做，[1, 0, 0, 0]"),s("li",null,"left，启动左侧推进器，[0, 1, 0, 0]"),s("li",null,"main，启动主推进器，[0, 0, 1, 0]"),s("li",null,"right，启动右侧推进器，[0, 0, 0, 1]")],-1),gs={class:"katex"},us=s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"x"),s("mo",null,"⃗")])]),s("annotation",{encoding:"application/x-tex"},"\\vec{x}")])])],-1),ds={class:"katex-html","aria-hidden":"true"},ys={class:"base"},vs=s("span",{class:"strut",style:{height:"0.714em"}},null,-1),_s={class:"mord accent"},bs={class:"vlist-t"},xs={class:"vlist-r"},fs={class:"vlist",style:{height:"0.714em"}},ks=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"x")],-1),ws={style:{top:"-3em"}},zs=s("span",{class:"pstrut",style:{height:"3em"}},null,-1),Rs={class:"accent-body",style:{left:"-0.2077em"}},Ms={class:"overlay",style:{height:"0.714em",width:"0.471em"}},Qs={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},Bs=s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1),As=[Bs],Ds=s("p",null,"需要注意的是，我们并不是输入状态就直接让它输出动作（纯粹的监督学习），而是让它输出 Q 函数。神经网络在这里只是强化学习的一个部分。",-1),Ls=s("p",null,"对于 Q 函数而言，这种方式的效果很好。那么到这里，问题就变成了：如何训练一个神经网络来输出 Q(s, a) 函数？",-1),Cs=s("h3",{id:"_3-3-构建训练集",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#_3-3-构建训练集"},[s("span",null,"3.3 构建训练集")])],-1),Es={class:"katex"},qs=s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"x"),s("mo",null,"⃗")])]),s("annotation",{encoding:"application/x-tex"},"\\vec{x}")])])],-1),Ts={class:"katex-html","aria-hidden":"true"},Fs={class:"base"},Ss=s("span",{class:"strut",style:{height:"0.714em"}},null,-1),Ns={class:"mord accent"},Ps={class:"vlist-t"},Gs={class:"vlist-r"},Zs={class:"vlist",style:{height:"0.714em"}},js=s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"x")],-1),Os={style:{top:"-3em"}},Vs=s("span",{class:"pstrut",style:{height:"3em"}},null,-1),Is={class:"accent-body",style:{left:"-0.2077em"}},Hs={class:"overlay",style:{height:"0.714em",width:"0.471em"}},Ys={xmlns:"http://www.w3.org/2000/svg",width:"0.471em",height:"0.714em",style:{width:"0.471em"},viewBox:"0 0 471 714",preserveAspectRatio:"xMinYMin"},Js=s("path",{d:`M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z`},null,-1),Ks=[Js],Us=l('<figure><img src="'+z+'" alt="11.13 通过贝尔曼方程构建训练集" width="560" tabindex="0" loading="lazy"><figcaption>11.13 通过贝尔曼方程构建训练集</figcaption></figure><p>我们将贝尔曼方程切分为两个部分，等式左边就是输入向量 x，等式右边就是输出 y。</p><p>问题的关键是，我们并不知道什么才是最佳的 Q 函数，能够将回报最大化的下一个状态和动作是什么我们不清楚。</p><p>没关系，我们可以取随机值，来构建一个，比如包含 1 万个数据的训练集。</p><h3 id="_3-4-deep-q-network-dqn" tabindex="-1"><a class="header-anchor" href="#_3-4-deep-q-network-dqn"><span>3.4 Deep Q-Network（DQN）</span></a></h3><p>通过前面几个小节，我们可以概括出神经网络构建的全过程：</p><p><strong>1. 初始化神经网络，随机的猜测 Q(s, a)。</strong></p><p>这就有点像训练线性回归模型时，随机的初始化所有参数，然后使用梯度下降一步一步完善。所以重要的其实是，算法能不能慢慢的改进参数，以获得更好的估计。</p><p><strong>2. 反复执行以下操作：</strong></p>',9),Ws=s("p",null,[a("2.1 在着陆期间，执行任何的操作，无论是好的还是坏的，你会获得多个这样的元组 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{separator:"true"},","),s("mi",null,"a"),s("mo",{separator:"true"},","),s("mi",null,"R"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{stretchy:"false"},")"),s("mo",{separator:"true"},","),s("msup",null,[s("mi",null,"s"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"(s, a, R(s), s')")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0019em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},")"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"s"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7519em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])]),s("span",{class:"mclose"},")")])])])],-1),Xs=s("p",null,"2.2 重放缓冲区（Replay Buffer）：储存最新的 1 万个元组数据。",-1),$s=s("p",null,[a("2.3 训练神经网络：将这 1 万个元组数据，通过贝尔曼方程构建成数据集。"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"m"),s("mi",null,"a"),s("mi",null,"x"),s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("msup",null,[s("mi",null,"s"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",{separator:"true"},","),s("msup",null,[s("mi",null,"a"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"maxQ(s', a')")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0019em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"ma"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"s"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7519em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7519em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])]),s("span",{class:"mclose"},")")])])]),a(" 最开始是随机初始化的，没关系，通过训练慢慢就会变成 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"Q"),s("mrow",null,[s("mi",null,"n"),s("mi",null,"e"),s("mi",null,"w")])]),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{separator:"true"},","),s("mi",null,"a"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"R"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{stretchy:"false"},")"),s("mo",null,"+"),s("mi",null,"γ"),s("mo",null,"⋅"),s("mrow",null,[s("mi",null,"max"),s("mo",null,"⁡"),s("mrow",null,[s("mi",null,"Q"),s("mo",{stretchy:"false"},"("),s("msup",null,[s("mi",null,"s"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",{separator:"true"},","),s("msup",null,[s("mi",null,"a"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")]),s("mo",{stretchy:"false"},")")])]),s("mo",null,"≈"),s("mi",null,"y")]),s("annotation",{encoding:"application/x-tex"},"Q_{new}(s, a)=R(s)+\\gamma\\cdot{\\max{Q(s', a')}} \\approx{y}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"n"),s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02691em"}},"w")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6389em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"⋅"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0019em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mop"},"max"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"s"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7519em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7519em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])]),s("span",{class:"mclose"},")")])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"≈"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")])])])])],-1),sa=s("p",null,[a("2.4 让 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"Q"),s("mo",null,"="),s("msub",null,[s("mi",null,"Q"),s("mrow",null,[s("mi",null,"n"),s("mi",null,"e"),s("mi",null,"w")])])]),s("annotation",{encoding:"application/x-tex"},"Q=Q_{new}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8778em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8778em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"n"),s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02691em"}},"w")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])])],-1),aa=l('<p>我们在反复执行训练神经网路的步骤中，Q(s, a) 是会继承上一次的训练结果的，所以每一次迭代，它都会变成更好的估计。</p><p>所以理论上来讲，只要你迭代的次数够多，训练的时间足够长，这个模拟着陆程序中的 DQN 就会变得足够好。</p><h2 id="_4-算法改进" tabindex="-1"><a class="header-anchor" href="#_4-算法改进"><span>4. 算法改进</span></a></h2><h3 id="_4-1-神经网络架构改进" tabindex="-1"><a class="header-anchor" href="#_4-1-神经网络架构改进"><span>4.1 神经网络架构改进</span></a></h3><figure><img src="'+c+'" alt="11.12 强化学习中的神经网络" width="560" tabindex="0" loading="lazy"><figcaption>11.12 强化学习中的神经网络</figcaption></figure><p>这是原本的神经网络模型，我们需要在每个状态上，分别对四个动作进行推理。也就是一个状态就要运行四次神经网络，或者说每个动作都对应一个神经网络，这是非常低效的。</p><figure><img src="'+R+'" alt="11.14 神经网络架构改进" width="560" tabindex="0" loading="lazy"><figcaption>11.14 神经网络架构改进</figcaption></figure><p>事实证明，在一个神经网络上同时计算并输出四个动作所对应的 Q 函数，效果会比原本的更好。因为通过贝尔曼方程，对比四个动作的回报，一次就可以知道在该状态下，做什么动作是最好的。</p><h3 id="_4-2-ε-贪婪策略-epsilon-greedy-policy" tabindex="-1"><a class="header-anchor" href="#_4-2-ε-贪婪策略-epsilon-greedy-policy"><span>4.2 ε-贪婪策略（Epsilon-greedy policy）</span></a></h3><p>当你处于某些状态时，可能并不想完全随机的采取行动，因为那样通常可能会是一个糟糕的结果。</p><p>我们原本的选项是：（1）选择一个动作 a，尽可能的最大化 Q(s, a)。即使它可能不尽人意，但是算法会尽力的使用我们当前对 Q(s, a)的猜测，并最大化它的收益。</p><p>而现在的选项是：<strong>（1）0.95 的概率，选择一个能最大化 Q(s, a)的动作 a。（2）0.05 的概率，随机选择一个动作 a。</strong></p><p>这么做的原因是，假设在随机初始化 Q(s ,a)的时候，出现了一些不好的情况，比如 Q(s, a)始终都很低，这可能导致该启动主推进器时，一直不启动的类似问题。</p><p>引入一个 0.05 的概率，神经网络可以学会克服自己的先入之见，也许自己之前坚持的才是错的呢？</p><p>这种随机选择动作的想法有时被称为探索步骤（Exploration Step）。还有一个很神奇的地方是，贪婪指的是 0.95 的概率，寻求 Q(s, a)最大化的部分，0.05 的随机探索才是不贪婪的。</p><p>一般来说，ε 的值是从大到小变化的。最初，你可能采取较多的随机行动，因为本身也不知道哪个好，哪个不好；</p><p>随着时间的推移，Q(s, a)迭代很多次后，已经有了很多好的推理，你可能会更倾向于用新的 Q(s, a)来估计和选择行动，所以随机行动就降低了。</p><h3 id="_4-3-超参数的敏感性" tabindex="-1"><a class="header-anchor" href="#_4-3-超参数的敏感性"><span>4.3 超参数的敏感性</span></a></h3><p>在监督学习中，超参数是不那么敏感的，比如，学习率选择的不好，可能也就是会让训练量或者说训练时间翻个两三倍。</p><p>但是强化学习中，超参数是很敏感的，假设你的 ε-贪婪策略中，epsilon 的值选的不够好，训练量可能会翻个 10 倍、100 倍。这非常恐怖。</p><p>吴恩达教授觉得，这可能是因为强化学习算法本身还不够完善导致的。目前，对于一个新项目而言，还需要我们自己试错。</p><h3 id="_4-4-小批量处理-mini-batch" tabindex="-1"><a class="header-anchor" href="#_4-4-小批量处理-mini-batch"><span>4.4 小批量处理（mini-batch）</span></a></h3><p>小批量处理可以加速强化学习和监督学习的训练速度，但是前提是你的训练集真的非常大，我们从监督学习的线性回归说起：</p><figure><img src="'+M+'" alt="11.15 小批量处理1" width="560" tabindex="0" loading="lazy"><figcaption>11.15 小批量处理1</figcaption></figure><p>这是最初的房价预测的线性回归模型，但是假设有 1 亿个训练样本，本来在梯度下降时，更新参数 w 和 b 就要循环迭代很多次，再乘一个 1 亿的样本基数，训练时间会大到难以想想。</p><p><mark>小批量处理要做的事情就是，将其划分为不同的集合，一个集合中 1000 个样本、5000 个样本……<strong>然后在进行成本函数计算时，第一次用集合 1 的样本，第二次用集合 2 的样本，依次类推</strong>。</mark></p><figure><img src="'+Q+'" alt="11.16 小批量处理2" width="560" tabindex="0" loading="lazy"><figcaption>11.16 小批量处理2</figcaption></figure><p>一次性处理（Batch learning）的结果是，梯度会直接的向最小的地方前进，但是数据量太大了，计算时间会非常长。</p><p>小批量处理（Mini-Batch learning）的优势在于，计算成本要低得多，所以当数据集很大的时候，它是一个更快的算法。一般会和别的算法一起用，比如 adam。</p><p>缺点也很明显，可能会因为不同集合的样本走歪路，虽然它也会最终趋向于全局最优化，但是它不是很可靠，并且会有噪点。</p><figure><img src="'+B+'" alt="11.17 小批量处理3" width="560" tabindex="0" loading="lazy"><figcaption>11.17 小批量处理3</figcaption></figure><p>回到强化学习中来，我们可以在训练神经网络模型的时候，使用小批量处理，将 1 万个数据，切分成 1000 个数据的不同集合。循环使用不同的集合来训练参数。</p><h3 id="_4-5-软更新" tabindex="-1"><a class="header-anchor" href="#_4-5-软更新"><span>4.5 软更新</span></a></h3><p>软更新可以帮助你的强化学习算法更好的收敛到一个好的解决方案。</p>',34),la=s("p",null,[a("在登月器的最后一步 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"Q"),s("mo",null,"="),s("msub",null,[s("mi",null,"Q"),s("mrow",null,[s("mi",null,"n"),s("mi",null,"e"),s("mi",null,"w")])])]),s("annotation",{encoding:"application/x-tex"},"Q=Q_{new}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8778em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8778em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"n"),s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02691em"}},"w")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(" 中，有一个隐患，假如遇到了像小批量处理时，数据集不好的情况下，新的 Q 值可能会更糟糕。")],-1),ta=s("figure",null,[s("img",{src:A,alt:"11.18 软更新",width:"560",tabindex:"0",loading:"lazy"}),s("figcaption",null,"11.18 软更新")],-1),na=s("p",null,"我们可以给新的参数乘一个 0.01，旧的参数乘一个 0.99，这就是软更新，因为我们只会接受一点点的新值，所以出现错误的可能性大大降低，并且收敛性也会变得更佳。",-1);function ea(ma,ia){const h=g("Tabs");return i(),m("div",null,[L,C,E,q,T,F,S,N,u(h,{id:"264",data:[{id:"简化版代码"},{id:"运行结果"}]},{title0:t(({value:n,isActive:e})=>[a("简化版代码")]),title1:t(({value:n,isActive:e})=>[a("运行结果")]),tab0:t(({value:n,isActive:e})=>[P]),tab1:t(({value:n,isActive:e})=>[G]),_:1}),Z,j,O,V,I,H,Y,J,K,U,W,X,$,ss,as,ls,ts,ns,es,ms,is,ps,rs,cs,hs,os,s("p",null,[a("所以这个由 12 个数字组成的列表或者说向量（8 个状态，4 个动作），我们将其写作神经网络的输入 "),s("span",gs,[us,s("span",ds,[s("span",ys,[vs,s("span",_s,[s("span",bs,[s("span",xs,[s("span",fs,[ks,s("span",ws,[zs,s("span",Rs,[s("span",Ms,[(i(),m("svg",Qs,As))])])])])])])])])])]),a("。")]),Ds,Ls,Cs,s("p",null,[a("首先，该方法将使用贝尔曼方程，来创建包含大量示例（x，y）的训练集，然后使用监督学习中的神经网络做模型训练，将 state-action（"),s("span",Es,[qs,s("span",Ts,[s("span",Fs,[Ss,s("span",Ns,[s("span",Ps,[s("span",Gs,[s("span",Zs,[js,s("span",Os,[Vs,s("span",Is,[s("span",Hs,[(i(),m("svg",Ys,Ks))])])])])])])])])])]),a("）映射到目标值 Q(s, a)（y）。")]),Us,Ws,Xs,$s,sa,aa,la,ta,na])}const ca=o(D,[["render",ea],["__file","11_reinforcement_learning.html.vue"]]),ha=JSON.parse('{"path":"/zh/intelligence/MachineLearning/11_reinforcement_learning.html","title":"3-3 强化学习","lang":"zh-CN","frontmatter":{"title":"3-3 强化学习","order":11,"author":"AOSAI","date":"2024-08-28T00:00:00.000Z","category":["机器学习"],"tag":["强化学习"],"description":"强化学习（Reinforcement Learning） 1. 强化学习概述 在机器学习中，强化学习与其说是一类算法，不如说是一种思想，就和 贪心、动态规划、分治、回溯 这些经典的解决思路一样。虽然目前尚未在商业领域中得到广泛应用，但它也是机器学习的支柱之一。 我们还是从一个例子开始，图 11.1 是斯坦福大学自主研发的遥感直升机，重 32 磅。与其他...","head":[["meta",{"property":"og:url","content":"https://mister-hope.github.io/blog-pages/zh/intelligence/MachineLearning/11_reinforcement_learning.html"}],["meta",{"property":"og:site_name","content":"青裁的博客"}],["meta",{"property":"og:title","content":"3-3 强化学习"}],["meta",{"property":"og:description","content":"强化学习（Reinforcement Learning） 1. 强化学习概述 在机器学习中，强化学习与其说是一类算法，不如说是一种思想，就和 贪心、动态规划、分治、回溯 这些经典的解决思路一样。虽然目前尚未在商业领域中得到广泛应用，但它也是机器学习的支柱之一。 我们还是从一个例子开始，图 11.1 是斯坦福大学自主研发的遥感直升机，重 32 磅。与其他..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://mister-hope.github.io/blog-pages/machinelearning/five/11-01.png =360x"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-08-28T14:28:20.000Z"}],["meta",{"property":"article:author","content":"AOSAI"}],["meta",{"property":"article:tag","content":"强化学习"}],["meta",{"property":"article:published_time","content":"2024-08-28T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-08-28T14:28:20.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"3-3 强化学习\\",\\"image\\":[\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-01.png =360x\\",\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-02.png =360x\\",\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-03.png =560x\\",\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-03.png =560x\\",\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-04.png =560x\\",\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-05.png =560x\\",\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-06.png =560x\\",\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-04.png =560x\\",\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-07.png =560x\\",\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-08.png =560x\\",\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-09.png =560x\\",\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-10.png =560x\\",\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-11.png =560x\\",\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-12.png =560x\\",\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-13.png =560x\\",\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-12.png =560x\\",\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-14.png =560x\\",\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-15.png =560x\\",\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-16.png =560x\\",\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-17.png =560x\\",\\"https://mister-hope.github.io/blog-pages/machinelearning/five/11-18.png =560x\\"],\\"datePublished\\":\\"2024-08-28T00:00:00.000Z\\",\\"dateModified\\":\\"2024-08-28T14:28:20.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"AOSAI\\"}]}"]]},"headers":[{"level":2,"title":"1. 强化学习概述","slug":"_1-强化学习概述","link":"#_1-强化学习概述","children":[{"level":3,"title":"1.1 什么是强化学习","slug":"_1-1-什么是强化学习","link":"#_1-1-什么是强化学习","children":[]},{"level":3,"title":"1.2 形式（火星探测器）","slug":"_1-2-形式-火星探测器","link":"#_1-2-形式-火星探测器","children":[]},{"level":3,"title":"1.3 回报（火星探测器）","slug":"_1-3-回报-火星探测器","link":"#_1-3-回报-火星探测器","children":[]},{"level":3,"title":"1.4 决策（火星探测器）","slug":"_1-4-决策-火星探测器","link":"#_1-4-决策-火星探测器","children":[]},{"level":3,"title":"1.5 回顾总结","slug":"_1-5-回顾总结","link":"#_1-5-回顾总结","children":[]}]},{"level":2,"title":"2. 状态-动作价值函数","slug":"_2-状态-动作价值函数","link":"#_2-状态-动作价值函数","children":[{"level":3,"title":"2.1 代码示例","slug":"_2-1-代码示例","link":"#_2-1-代码示例","children":[]},{"level":3,"title":"2.2 贝尔曼方程（Bellman Equation）","slug":"_2-2-贝尔曼方程-bellman-equation","link":"#_2-2-贝尔曼方程-bellman-equation","children":[]},{"level":3,"title":"2.3 随机环境","slug":"_2-3-随机环境","link":"#_2-3-随机环境","children":[]}]},{"level":2,"title":"3. 连续的状态空间","slug":"_3-连续的状态空间","link":"#_3-连续的状态空间","children":[{"level":3,"title":"3.1 登月器","slug":"_3-1-登月器","link":"#_3-1-登月器","children":[]},{"level":3,"title":"3.2 强化学习中的神经网络","slug":"_3-2-强化学习中的神经网络","link":"#_3-2-强化学习中的神经网络","children":[]},{"level":3,"title":"3.3 构建训练集","slug":"_3-3-构建训练集","link":"#_3-3-构建训练集","children":[]},{"level":3,"title":"3.4 Deep Q-Network（DQN）","slug":"_3-4-deep-q-network-dqn","link":"#_3-4-deep-q-network-dqn","children":[]}]},{"level":2,"title":"4. 算法改进","slug":"_4-算法改进","link":"#_4-算法改进","children":[{"level":3,"title":"4.1 神经网络架构改进","slug":"_4-1-神经网络架构改进","link":"#_4-1-神经网络架构改进","children":[]},{"level":3,"title":"4.2 ε-贪婪策略（Epsilon-greedy policy）","slug":"_4-2-ε-贪婪策略-epsilon-greedy-policy","link":"#_4-2-ε-贪婪策略-epsilon-greedy-policy","children":[]},{"level":3,"title":"4.3 超参数的敏感性","slug":"_4-3-超参数的敏感性","link":"#_4-3-超参数的敏感性","children":[]},{"level":3,"title":"4.4 小批量处理（mini-batch）","slug":"_4-4-小批量处理-mini-batch","link":"#_4-4-小批量处理-mini-batch","children":[]},{"level":3,"title":"4.5 软更新","slug":"_4-5-软更新","link":"#_4-5-软更新","children":[]}]}],"git":{"createdTime":1723830205000,"updatedTime":1724855300000,"contributors":[{"name":"zjk-laptop","email":"zhangjk2021@gmail.com","commits":2}]},"readingTime":{"minutes":22.53,"words":6758},"filePathRelative":"zh/intelligence/MachineLearning/11_reinforcement_learning.md","localizedDate":"2024年8月28日","excerpt":"<p>强化学习（Reinforcement Learning）</p>\\n<h2>1. 强化学习概述</h2>\\n<p>在机器学习中，强化学习与其说是一类算法，不如说是一种思想，就和 <strong>贪心、动态规划、分治、回溯</strong> 这些经典的解决思路一样。虽然目前尚未在商业领域中得到广泛应用，但它也是机器学习的支柱之一。</p>\\n<p>我们还是从一个例子开始，图 11.1 是斯坦福大学自主研发的遥感直升机，重 32 磅。与其他遥感直升机一样，它配备了机载计算机、GPS、加速度计、陀螺仪和磁罗盘，因此它可以随时非常准确的知道自己的位置。</p>\\n<div class=\\"layout\\">\\n<figure><img src=\\"/machinelearning/five/11-01.png\\" alt=\\"11.1 强化学习-遥感直升机1\\" width=\\"360\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>11.1 强化学习-遥感直升机1</figcaption></figure>\\n<figure><img src=\\"/machinelearning/five/11-02.png\\" alt=\\"11.2 强化学习-遥感直升机2\\" width=\\"360\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>11.2 强化学习-遥感直升机2</figcaption></figure>\\n</div>","autoDesc":true}');export{ca as comp,ha as data};
